{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 22:33:40,320 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/saisuryamadhav/Library/Caches/pypoetry/virtualenvs/backend-dSPC7ywe-py3.12/lib/python3.12/site-packages/pinecone_plugins'])\n",
      "2024-11-03 22:33:40,324 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2024-11-03 22:33:40,324 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n",
      "2024-11-03 22:33:40,664 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2024-11-03 22:33:46,132 - sentence_transformers.SentenceTransformer - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import logging\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "import pymupdf as fitz\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from llama_index.core import Document, Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "import logging\n",
    "from llama_index.core import Settings, StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.readers.file import PDFReader\n",
    "from datetime import datetime\n",
    "from llama_index.core import Document, Settings, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from typing import Sequence\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import pymupdf as fitz\n",
    "import llama_index.core\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxxxxxx\"\n",
    "pc = Pinecone(api_key=\"xxxxxxx\")\n",
    "\n",
    "\n",
    "\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "            embed_batch_size=10\n",
    "        )\n",
    "Settings.embed_model = embed_model\n",
    "Settings.dimension = 384\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", api_base=\"https://models.inference.ai.azure.com\")\n",
    "def optimize_metadata(metadata: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Convert complex metadata types to simple types that Pinecone accepts.\n",
    "    Pinecone only accepts strings, numbers, booleans, or lists of strings.\n",
    "    \"\"\"\n",
    "    optimized = {}\n",
    "    \n",
    "    # Handle essential fields\n",
    "    essential_fields = ['source', 'type', 'page_num']\n",
    "    for field in essential_fields:\n",
    "        if field in metadata:\n",
    "            optimized[field] = str(metadata[field])\n",
    "    \n",
    "    # Handle bbox - convert to string representation\n",
    "    if 'bbox' in metadata:\n",
    "        bbox = metadata['bbox']\n",
    "        optimized['bbox_str'] = f\"{bbox['x1']},{bbox['y1']},{bbox['x2']},{bbox['y2']}\"\n",
    "    \n",
    "    # Handle paths - store just the filenames\n",
    "    if 'image' in metadata:\n",
    "        optimized['image_filename'] = os.path.basename(metadata['image'])\n",
    "    if 'dataframe' in metadata:\n",
    "        optimized['excel_filename'] = os.path.basename(metadata['dataframe'])\n",
    "    \n",
    "    # Handle captions\n",
    "    if 'caption' in metadata:\n",
    "        optimized['caption'] = str(metadata['caption'])[:512]  # Limit caption length\n",
    "    \n",
    "    return optimized\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('document_processing.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "import pymupdf as fitz\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from llama_index.core import Document, Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "def optimize_metadata(metadata: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Convert complex metadata types to simple types that Pinecone accepts.\n",
    "    Pinecone only accepts strings, numbers, booleans, or lists of strings.\n",
    "    \"\"\"\n",
    "    optimized = {}\n",
    "    \n",
    "    # Handle essential fields\n",
    "    essential_fields = ['source', 'type', 'page_num']\n",
    "    for field in essential_fields:\n",
    "        if field in metadata:\n",
    "            optimized[field] = str(metadata[field])\n",
    "    \n",
    "    # Handle bbox - convert to string representation\n",
    "    if 'bbox' in metadata:\n",
    "        bbox = metadata['bbox']\n",
    "        optimized['bbox_str'] = f\"{bbox['x1']},{bbox['y1']},{bbox['x2']},{bbox['y2']}\"\n",
    "    \n",
    "    # Handle paths - store just the filenames\n",
    "    if 'image' in metadata:\n",
    "        optimized['image_filename'] = os.path.basename(metadata['image'])\n",
    "    if 'dataframe' in metadata:\n",
    "        optimized['excel_filename'] = os.path.basename(metadata['dataframe'])\n",
    "    \n",
    "    # Handle captions\n",
    "    if 'caption' in metadata:\n",
    "        optimized['caption'] = str(metadata['caption'])[:512]  # Limit caption length\n",
    "    \n",
    "    return optimized\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('document_processing.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ProcessingMetrics:\n",
    "    start_time: datetime\n",
    "    end_time: Optional[datetime] = None\n",
    "    document_count: int = 0\n",
    "    total_tokens: int = 0\n",
    "    total_characters: int = 0\n",
    "    processed_files: List[str] = None\n",
    "    errors: List[Dict] = None\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def log_error(self, filename: str, error: Exception):\n",
    "        if self.errors is None:\n",
    "            self.errors = []\n",
    "        self.errors.append({\n",
    "            \"filename\": filename,\n",
    "            \"error\": str(error),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "@dataclass\n",
    "class DocumentElement:\n",
    "    content: Any\n",
    "    element_type: str\n",
    "    page_num: int\n",
    "    bbox: str\n",
    "    source_file: str\n",
    "    element_id: str\n",
    "    citations: List[str] = None\n",
    "    \n",
    "    def to_document(self) -> Document:\n",
    "        metadata = {\n",
    "            \"type\": self.element_type,\n",
    "            \"page_num\": self.page_num,\n",
    "            \"bbox\": self.bbox,\n",
    "            \"source\": self.source_file,\n",
    "            \"element_id\": self.element_id,\n",
    "            \"citations\": self.citations or []\n",
    "        }\n",
    "        \n",
    "        if self.element_type == \"table\":\n",
    "            metadata[\"table_path\"] = self.content[\"table_path\"]\n",
    "            text = f\"Table with caption: {self.content['caption']}\\nColumns: {self.content['columns']}\"\n",
    "        elif self.element_type == \"image\":\n",
    "            metadata[\"image_path\"] = self.content[\"image_path\"]\n",
    "            text = f\"Image with caption: {self.content['caption']}\"\n",
    "        else:\n",
    "            text = self.content\n",
    "            \n",
    "        return Document(text=text, metadata=metadata, id_=self.element_id)\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        self.metrics = ProcessingMetrics(\n",
    "            start_time=datetime.now(),\n",
    "            processed_files=[],\n",
    "            errors=[]\n",
    "        )\n",
    "        \n",
    "        # Initialize models\n",
    "        self.vision_model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.vision_model.to(self.device)\n",
    "        \n",
    "        logger.info(f\"Initialized DocumentProcessor with device: {self.device}\")\n",
    "\n",
    "    def process_text_block(self, text_block: tuple, page_num: int, source_file: str, block_id: int) -> DocumentElement:\n",
    "        \"\"\"Process a text block from PDF.\"\"\"\n",
    "        logger.debug(f\"Processing text block {block_id} from page {page_num}\")\n",
    "        \n",
    "        bbox = {\n",
    "            \"x1\": text_block[0], \n",
    "            \"y1\": text_block[1],\n",
    "            \"x2\": text_block[2], \n",
    "            \"y2\": text_block[3]\n",
    "        }\n",
    "        bbox = f\"{bbox['x1']},{bbox['y1']},{bbox['x2']},{bbox['y2']}\"\n",
    "        \n",
    "        self.metrics.total_characters += len(text_block[4])\n",
    "        # Approximate token count\n",
    "        self.metrics.total_tokens += len(text_block[4].split())\n",
    "        \n",
    "        return DocumentElement(\n",
    "            content=text_block[4],\n",
    "            element_type=\"text\",\n",
    "            page_num=page_num,\n",
    "            bbox=bbox,\n",
    "            source_file=source_file,\n",
    "            element_id=f\"{source_file}-page{page_num}-block{block_id}\"\n",
    "        )\n",
    "\n",
    "    def process_table(self, table, page_num: int, source_file: str, table_id: int, \n",
    "                     save_dir: str) -> DocumentElement:\n",
    "        \"\"\"Process a table from PDF.\"\"\"\n",
    "        logger.debug(f\"Processing table {table_id} from page {page_num}\")\n",
    "        \n",
    "        df = table.to_pandas()\n",
    "        table_path = os.path.join(save_dir, f\"table-{table_id}-page-{page_num}.xlsx\")\n",
    "        df.to_excel(table_path, index=False)\n",
    "        \n",
    "        content = {\n",
    "            \"table_path\": table_path,\n",
    "            \"caption\": f\"Table extracted from page {page_num}\",\n",
    "            \"columns\": \", \".join(df.columns.tolist())\n",
    "        }\n",
    "        \n",
    "        # Update metrics\n",
    "        self.metrics.total_characters += sum(df.astype(str).sum().sum())\n",
    "        self.metrics.total_tokens += len(df.columns) * df.shape[0]  # Approximate\n",
    "        \n",
    "        return DocumentElement(\n",
    "            content=content,\n",
    "            element_type=\"table\",\n",
    "            page_num=page_num,\n",
    "            bbox=f\"{table.bbox['x1']},{table.bbox['y1']},{table.bbox['x2']},{table.bbox['y2']}\",\n",
    "            source_file=source_file,\n",
    "            element_id=f\"{source_file}-page{page_num}-table{table_id}\"\n",
    "        )\n",
    "\n",
    "    def describe_image(self, image_content: bytes) -> str:\n",
    "        \"\"\"Generate a text description of the image using a pre-trained model.\"\"\"\n",
    "        logger.debug(\"Generating image description\")\n",
    "        \n",
    "        image = Image.open(io.BytesIO(image_content)).convert('RGB')\n",
    "        pixel_values = self.feature_extractor(images=[image], return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.to(self.device)\n",
    "\n",
    "        output_ids = self.vision_model.generate(\n",
    "            pixel_values,\n",
    "            max_length=16,\n",
    "            num_beams=4\n",
    "        )\n",
    "\n",
    "        preds = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        description = preds[0].strip()\n",
    "        \n",
    "        # Update metrics\n",
    "        self.metrics.total_characters += len(description)\n",
    "        self.metrics.total_tokens += len(description.split())\n",
    "        \n",
    "        return description\n",
    "\n",
    "    def is_graph(self, image_data: bytes) -> bool:\n",
    "        \"\"\"Detect if the image contains a graph.\"\"\"\n",
    "        logger.debug(\"Checking if image is a graph\")\n",
    "        \n",
    "        nparr = np.frombuffer(image_data, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "        \n",
    "        return lines is not None and len(lines) > 10\n",
    "\n",
    "    def process_graph(self, image_data: bytes) -> str:\n",
    "        \"\"\"Process a graph image to extract basic information.\"\"\"\n",
    "        logger.debug(\"Processing graph\")\n",
    "        \n",
    "        nparr = np.frombuffer(image_data, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "        \n",
    "        horizontal_lines = 0\n",
    "        vertical_lines = 0\n",
    "        \n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                rho, theta = line[0]\n",
    "                if np.abs(theta) < np.pi / 4 or np.abs(theta - np.pi) < np.pi / 4:\n",
    "                    vertical_lines += 1\n",
    "                else:\n",
    "                    horizontal_lines += 1\n",
    "        \n",
    "        graph_type = \"bar graph\" if vertical_lines > horizontal_lines else \\\n",
    "                    \"line graph\" if horizontal_lines > vertical_lines else \\\n",
    "                    \"scatter plot\"\n",
    "        \n",
    "        description = f\"This image appears to be a {graph_type} with approximately {vertical_lines} vertical lines and {horizontal_lines} horizontal lines.\"\n",
    "        \n",
    "        # Update metrics\n",
    "        self.metrics.total_characters += len(description)\n",
    "        self.metrics.total_tokens += len(description.split())\n",
    "        \n",
    "        return description\n",
    "\n",
    "    def parse_all_tables(self, filename: str, page, pagenum: int, text_blocks, ongoing_tables) -> Tuple[List[Document], List, Any]:\n",
    "        \"\"\"Extract tables from a PDF page.\"\"\"\n",
    "        logger.debug(f\"Parsing tables from page {pagenum}\")\n",
    "        \n",
    "        table_docs = []\n",
    "        table_bboxes = []\n",
    "        \n",
    "        try:\n",
    "            tables = page.find_tables(\n",
    "                horizontal_strategy=\"lines_strict\",\n",
    "                vertical_strategy=\"lines_strict\"\n",
    "            )\n",
    "            \n",
    "            tablerefdir = os.path.join(os.getcwd(), \"vectorstore/table_references\")\n",
    "            os.makedirs(tablerefdir, exist_ok=True)\n",
    "            \n",
    "            for tab in tables:\n",
    "                if not tab.header.external:\n",
    "                    continue\n",
    "                \n",
    "                pandas_df = tab.to_pandas()\n",
    "                df_xlsx_path = os.path.join(\n",
    "                    tablerefdir,\n",
    "                    f\"table{len(table_docs)+1}-page{pagenum}.xlsx\"\n",
    "                )\n",
    "                pandas_df.to_excel(df_xlsx_path)\n",
    "                \n",
    "                bbox = fitz.Rect(tab.bbox)\n",
    "                table_bboxes.append(bbox)\n",
    "                \n",
    "                # Extract surrounding text\n",
    "                before_text, after_text = self.extract_text_around_item(\n",
    "                    text_blocks,\n",
    "                    bbox,\n",
    "                    page.rect.height\n",
    "                )\n",
    "                \n",
    "                # Save table image\n",
    "                table_img = page.get_pixmap(clip=bbox)\n",
    "                table_img_path = os.path.join(\n",
    "                    tablerefdir,\n",
    "                    f\"table{len(table_docs)+1}-page{pagenum}.jpg\"\n",
    "                )\n",
    "                table_img.save(table_img_path)\n",
    "                \n",
    "                description = self.process_graph(table_img.tobytes())\n",
    "                caption = before_text.replace(\"\\n\", \" \") + description + after_text.replace(\"\\n\", \" \")\n",
    "                if before_text == \"\" and after_text == \"\":\n",
    "                    caption = \" \".join(tab.header.names)\n",
    "                \n",
    "                table_metadata = {\n",
    "                    \"source\": f\"{filename[:-4]}-page{pagenum}-table{len(table_docs)+1}\",\n",
    "                    \"excel_path\": df_xlsx_path,\n",
    "                    \"image_path\": table_img_path,\n",
    "                    \"caption\": caption,\n",
    "                    \"type\": \"table\",\n",
    "                    \"page_num\": pagenum,\n",
    "                    \"columns\": list(pandas_df.columns.values),\n",
    "                    \"markdown_table\": pandas_df.to_markdown(),\n",
    "                    \"html_table\": pandas_df.to_html()\n",
    "                }\n",
    "                \n",
    "                doc_text = (\n",
    "                    f\"Table Reference: {table_metadata['markdown_table']}\\n\"\n",
    "                    f\"Caption: {caption}\\n\"\n",
    "                    f\"Excel File: {df_xlsx_path}\\n\"\n",
    "                    f\"Table Image: ![Table]({table_img_path})\"\n",
    "                )\n",
    "                optimized_metadata = optimize_metadata(table_metadata)\n",
    "                table_docs.append(Document(\n",
    "                    text=doc_text,\n",
    "                    metadata=optimized_metadata\n",
    "                ))\n",
    "                \n",
    "                # Update metrics\n",
    "                self.metrics.total_characters += len(doc_text)\n",
    "                self.metrics.total_tokens += len(doc_text.split())\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing tables on page {pagenum}: {e}\")\n",
    "            self.metrics.log_error(filename, e)\n",
    "        \n",
    "        return table_docs, table_bboxes, ongoing_tables\n",
    "\n",
    "    def load_data_from_directory(self, directory: str) -> List[Document]:\n",
    "        \"\"\"Load and process multiple file types from a directory.\"\"\"\n",
    "        logger.info(f\"Processing directory: {directory}\")\n",
    "        \n",
    "        documents = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            file_extension = os.path.splitext(filename.lower())[1]\n",
    "            \n",
    "            logger.info(f\"Processing file: {filename}\")\n",
    "            self.metrics.processed_files.append(filename)\n",
    "            \n",
    "            try:\n",
    "                if file_extension in ('.png', '.jpg', '.jpeg'):\n",
    "                    with open(filepath, \"rb\") as image_file:\n",
    "                        image_content = image_file.read()\n",
    "                        image_text = self.describe_image(image_content)\n",
    "                        doc = Document(\n",
    "                            text=image_text,\n",
    "                            metadata={\"source\": filename, \"type\": \"image\"}\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "                \n",
    "                elif file_extension == '.pdf':\n",
    "                    with open(filepath, \"rb\") as pdf_file:\n",
    "                        pdf_documents = self.get_pdf_documents(pdf_file)\n",
    "                        documents.extend(pdf_documents)\n",
    "                \n",
    "                elif file_extension in ('.ppt', '.pptx'):\n",
    "                    ppt_documents = self.process_ppt_file(filepath)\n",
    "                    documents.extend(ppt_documents)\n",
    "                \n",
    "                else:\n",
    "                    with open(filepath, \"r\", encoding=\"utf-8\") as text_file:\n",
    "                        text = text_file.read()\n",
    "                        doc = Document(\n",
    "                            text=text,\n",
    "                            metadata={\"source\": filename, \"type\": \"text\"}\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "                \n",
    "                self.metrics.document_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {filename}: {e}\")\n",
    "                self.metrics.log_error(filename, e)\n",
    "                continue\n",
    "        \n",
    "        return documents\n",
    "\n",
    "    def export_metrics(self, output_path: str = \"processing_metrics.json\"):\n",
    "        \"\"\"Export processing metrics to JSON file.\"\"\"\n",
    "        self.metrics.end_time = datetime.now()\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(self.metrics.to_dict(), f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"Metrics exported to {output_path}\")\n",
    "        \n",
    "        return self.metrics.to_dict()\n",
    "\n",
    "    # Helper method that needs to be implemented\n",
    "    # ... [Previous code remains the same until extract_text_around_item] ...\n",
    "\n",
    "    def extract_text_around_item(self, text_blocks, bbox, page_height, context_distance: float = 50.0) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Extract text before and after an item on the page within a specified distance.\n",
    "        \n",
    "        Args:\n",
    "            text_blocks: List of text blocks from the page\n",
    "            bbox: Bounding box of the item (table/image)\n",
    "            page_height: Height of the page\n",
    "            context_distance: Distance in points to look for context (default: 50.0)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[str, str]: (text before item, text after item)\n",
    "        \"\"\"\n",
    "        logger.debug(\"Extracting text around item\")\n",
    "        \n",
    "        # Convert bbox to coordinates if it's not already\n",
    "        if isinstance(bbox, dict):\n",
    "            item_top = bbox['y1']\n",
    "            item_bottom = bbox['y2']\n",
    "        else:\n",
    "            item_top = bbox.y0\n",
    "            item_bottom = bbox.y1\n",
    "            \n",
    "        before_text = []\n",
    "        after_text = []\n",
    "        \n",
    "        for block in text_blocks:\n",
    "            # Get the vertical position of the text block\n",
    "            block_bottom = block[3]  # y2\n",
    "            block_top = block[1]     # y1\n",
    "            block_text = block[4]    # text content\n",
    "            \n",
    "            # Check if text is before the item\n",
    "            if block_bottom < item_top and (item_top - block_bottom) <= context_distance:\n",
    "                before_text.append(block_text)\n",
    "                \n",
    "            # Check if text is after the item\n",
    "            elif block_top > item_bottom and (block_top - item_bottom) <= context_distance:\n",
    "                after_text.append(block_text)\n",
    "        \n",
    "        return \" \".join(before_text), \" \".join(after_text)\n",
    "\n",
    "    def get_pdf_documents(self, pdf_file) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Process PDF file and return list of documents.\n",
    "        \n",
    "        Args:\n",
    "            pdf_file: File object of the PDF\n",
    "            \n",
    "        Returns:\n",
    "            List[Document]: List of processed documents\n",
    "        \"\"\"\n",
    "        logger.info(\"Processing PDF file\")\n",
    "        \n",
    "        try:\n",
    "            # Load PDF\n",
    "            pdf_document = fitz.open(stream=pdf_file.read())\n",
    "            documents = []\n",
    "            \n",
    "            for page_num in range(len(pdf_document)):\n",
    "                page = pdf_document[page_num]\n",
    "                \n",
    "                # Get text blocks\n",
    "                text_blocks = page.get_text(\"blocks\")\n",
    "                \n",
    "                # Process tables first\n",
    "                table_docs, table_bboxes, _ = self.parse_all_tables(\n",
    "                    pdf_file.name,\n",
    "                    page,\n",
    "                    page_num + 1,\n",
    "                    text_blocks,\n",
    "                    None\n",
    "                )\n",
    "                documents.extend(table_docs)\n",
    "                \n",
    "                # Process remaining text blocks\n",
    "                for block_id, block in enumerate(text_blocks):\n",
    "                    # Skip if block overlaps with any table\n",
    "                    block_rect = fitz.Rect(block[:4])\n",
    "                    skip_block = any(block_rect.intersects(table_bbox) for table_bbox in table_bboxes)\n",
    "                    \n",
    "                    if not skip_block:\n",
    "                        doc_element = self.process_text_block(\n",
    "                            block,\n",
    "                            page_num + 1,\n",
    "                            pdf_file.name,\n",
    "                            block_id\n",
    "                        )\n",
    "                        documents.append(doc_element.to_document())\n",
    "                \n",
    "                # Process images\n",
    "                images = page.get_images(full=True)\n",
    "                for img_id, img_info in enumerate(images):\n",
    "                    xref = img_info[0]\n",
    "                    base_image = pdf_document.extract_image(xref)\n",
    "                    \n",
    "                    if base_image:\n",
    "                        image_data = base_image[\"image\"]\n",
    "                        \n",
    "                        # Process as graph if detected\n",
    "                        if self.is_graph(image_data):\n",
    "                            description = self.process_graph(image_data)\n",
    "                        else:\n",
    "                            description = self.describe_image(image_data)\n",
    "                        \n",
    "                        # Create image document\n",
    "                        doc = Document(\n",
    "                            text=description,\n",
    "                            metadata={\n",
    "                                \"source\": pdf_file.name,\n",
    "                                \"type\": \"image\",\n",
    "                                \"page_num\": page_num + 1,\n",
    "                                \"image_id\": img_id\n",
    "                            }\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "            \n",
    "            return documents\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PDF: {e}\")\n",
    "            self.metrics.log_error(pdf_file.name, e)\n",
    "            return []\n",
    "\n",
    "    def process_ppt_file(self, filepath: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Process PowerPoint file and return list of documents.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the PowerPoint file\n",
    "            \n",
    "        Returns:\n",
    "            List[Document]: List of processed documents\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing PowerPoint file: {filepath}\")\n",
    "        \n",
    "        try:\n",
    "            from pptx import Presentation\n",
    "            \n",
    "            documents = []\n",
    "            prs = Presentation(filepath)\n",
    "            \n",
    "            for slide_num, slide in enumerate(prs.slides, 1):\n",
    "                # Process text content\n",
    "                text_content = []\n",
    "                \n",
    "                for shape in slide.shapes:\n",
    "                    if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                        text_content.append(shape.text.strip())\n",
    "                        \n",
    "                        # Update metrics\n",
    "                        self.metrics.total_characters += len(shape.text)\n",
    "                        self.metrics.total_tokens += len(shape.text.split())\n",
    "                \n",
    "                if text_content:\n",
    "                    doc = Document(\n",
    "                        text=\"\\n\".join(text_content),\n",
    "                        metadata={\n",
    "                            \"source\": filepath,\n",
    "                            \"type\": \"presentation\",\n",
    "                            \"slide_num\": slide_num\n",
    "                        }\n",
    "                    )\n",
    "                    documents.append(doc)\n",
    "                \n",
    "                # Process images in the slide\n",
    "                for shape in slide.shapes:\n",
    "                    if hasattr(shape, \"image\"):\n",
    "                        try:\n",
    "                            # Save image temporarily\n",
    "                            image_bytes = shape.image.blob\n",
    "                            \n",
    "                            # Process as graph if detected\n",
    "                            if self.is_graph(image_bytes):\n",
    "                                description = self.process_graph(image_bytes)\n",
    "                            else:\n",
    "                                description = self.describe_image(image_bytes)\n",
    "                            \n",
    "                            doc = Document(\n",
    "                                text=description,\n",
    "                                metadata={\n",
    "                                    \"source\": filepath,\n",
    "                                    \"type\": \"presentation_image\",\n",
    "                                    \"slide_num\": slide_num\n",
    "                                }\n",
    "                            )\n",
    "                            documents.append(doc)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Error processing image in slide {slide_num}: {e}\")\n",
    "                            continue\n",
    "            \n",
    "            return documents\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PowerPoint file: {e}\")\n",
    "            self.metrics.log_error(filepath, e)\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "def initialize_vector_store(index_name: str = \"document-store\") -> PineconeVectorStore:\n",
    "    \"\"\"Initialize Pinecone vector store with the new client.\"\"\"\n",
    "    \n",
    "    # Initialize Pinecone client\n",
    "    pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "    \n",
    "    # Check if index exists, if not create it\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=Settings.dimension,  # OpenAI embedding dimension\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Initialize vector store\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index_name=index_name,\n",
    "        environment=os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
    "    )\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_engine(index: VectorStoreIndex):\n",
    "    \"\"\"Create a query engine with specific configurations.\"\"\"\n",
    "    return index.as_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        response_mode=\"tree_summarize\"\n",
    "    )\n",
    "\n",
    "def search_documents(query: str, index: VectorStoreIndex, \n",
    "                    filters: Dict = None) -> Dict:\n",
    "    \"\"\"Search documents with optional filters.\"\"\"\n",
    "    query_engine = create_query_engine(index)\n",
    "    response = query_engine.query(query)\n",
    "    \n",
    "    # Extract source nodes and metadata\n",
    "    sources = []\n",
    "    for node in response.source_nodes:\n",
    "        sources.append({\n",
    "            \"text\": node.text,\n",
    "            \"metadata\": node.metadata,\n",
    "            \"score\": node.score\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"sources\": sources\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"input_directory\": \"/Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf\",\n",
    "    \"pinecone_api_key\": \"xxxxxxx\",\n",
    "    \"pinecone_environment\": \"us-east1-gcp\",\n",
    "    \"openai_api_key\": \"xxxxxxx\",\n",
    "    \"index_name\": \"document-store\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    input_directory: str,\n",
    "    pinecone_api_key: str,\n",
    "    pinecone_environment: str,\n",
    "    openai_api_key: str,\n",
    "    index_name: str = \"document-store\",\n",
    "    batch_size: int = 100\n",
    ") -> Optional[VectorStoreIndex]:\n",
    "    \"\"\"\n",
    "    Main function to process documents and create searchable index.\n",
    "    \n",
    "    Args:\n",
    "        input_directory: Path to directory containing PDFs\n",
    "        pinecone_api_key: Pinecone API key\n",
    "        pinecone_environment: Pinecone environment\n",
    "        openai_api_key: OpenAI API key\n",
    "        index_name: Name of the Pinecone index\n",
    "        batch_size: Number of documents to process in each batch\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up environment variables\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
    "        os.environ[\"PINECONE_ENVIRONMENT\"] = pinecone_environment\n",
    "\n",
    "        \n",
    "        from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "        # Initialize the embedding model        \n",
    "        # Initialize Pinecone\n",
    "        vector_store = initialize_vector_store()\n",
    "\n",
    "        # Create storage context\n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            vector_store=vector_store\n",
    "        )\n",
    "\n",
    "        # Process documents\n",
    "        print(f\"Processing documents from {input_directory}\")\n",
    "        processor = DocumentProcessor()\n",
    "        documents = processor.load_data_from_directory(input_directory)\n",
    "        \n",
    "        if not documents:\n",
    "            print(\"No documents were processed successfully.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Successfully processed {len(documents)} documents\")\n",
    "        \n",
    "        # Create index\n",
    "        print(\"Creating vector index...\")\n",
    "        index = VectorStoreIndex.from_documents(\n",
    "            documents,\n",
    "            storage_context=storage_context,\n",
    "            show_progress=True\n",
    "        )\n",
    "        \n",
    "        print(\"Index created successfully!\")\n",
    "        \n",
    "        \n",
    "        return index\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 19:22:40,014 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/saisuryamadhav/Library/Caches/pypoetry/virtualenvs/backend-dSPC7ywe-py3.12/lib/python3.12/site-packages/pinecone_plugins'])\n",
      "2024-11-03 19:22:40,016 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2024-11-03 19:22:40,016 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n",
      "2024-11-03 19:22:40,214 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/saisuryamadhav/Library/Caches/pypoetry/virtualenvs/backend-dSPC7ywe-py3.12/lib/python3.12/site-packages/pinecone_plugins'])\n",
      "2024-11-03 19:22:40,215 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2024-11-03 19:22:40,215 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents from /Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.46.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'> is overwritten by shared decoder config: GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2024-11-03 19:22:49,486 - __main__ - INFO - Initialized DocumentProcessor with device: cpu\n",
      "2024-11-03 19:22:49,492 - __main__ - INFO - Processing directory: /Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf\n",
      "2024-11-03 19:22:49,492 - __main__ - INFO - Processing file: Beyond Active and Passive Investing_ The Customization of Finance.pdf\n",
      "2024-11-03 19:22:49,493 - __main__ - INFO - Processing PDF file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 1567 documents\n",
      "Creating vector index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2cc6def83845eabac5ac5fdd033926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c22dee93bf47a0aba85797ccaa8ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5479e29fc530465ba2b6a827429200cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd1c3f2fa364000a80a1f5078889580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b2362e0a044a5ea3120d7254078beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c59e25804944eb9290ea48e8f5095e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d77b735d3940d686856fb69282d6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4096d82d3941e4bc4a3b85edd11ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a536c58f9c13478ab9abaed0786bae1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1305c48ebc7748a4980911900e807a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48eeefa524274889b331ccca8530cf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7943b0fbc8a4aafbf470c8f94619076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1da0695115c4325889b2140c278d66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1dc7c42541424e8b8ee4071d2f2a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40deeb7f3f2b47969116492c000c27bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e49e862df04a92a161d77f7faa0804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e388f8908d4070b20beb1e454fd983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcedc03a7fa4437aaaffd2f594e876e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b856a415e3144feea7dd2e7e9c2e121d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc82b4298df479086cf8082937720c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6709ef27099c48c1b4ff132d6b45bbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59b7e32ca96439d98d9833013a172a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bd239eb4f54f97a4829f2e8472062a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2cd021b8894524979a97b88482d82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05854fe5387244249a4c129f6f703338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c71a480999541e298caf50ec6307ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb15239265bc403a9c0adb36217a6f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed49ae67ef740a19f12dcb8162458c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9803c79d9d2411f8f16b10098c12202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a26aa2a450e4c778b552eaad91eb5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4474175d9f340b4b5928d4a71a7a30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1275235c3e9474c8e634273fb8d5410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1b9d4944a54b1f8cfdcf6b9369de82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f6a0639f3449079fc6a33dccd44d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f971b5fe2db400db92ffd312d3f3aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b896d430ac4663b1f9df897fbe4712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a65b5baa80446a849d271e7c39ffe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ffd72598114b0fbbfd80d5219d4547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68b1c49516f40d5a7e1b63bd5392eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acdd564a080447daceae6f3f53ea1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12364eb60b6e446c986aa46e38448d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178be23488d94a8aa7b2af0c916f6ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752947f0c07d49069e47b03eb58370fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96d3801e7f44bc4be1194cd3c1e9277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2169771d8c884ea9800f7f8a9b545468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107151c7669745d19767c174387c852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba2fbb4f3964ebe90807cb37a01c29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c0abc78142469dad082e23ad11edd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57993773f06948acb3fd9a9891bdd585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c876810ce214583bbb29c1595880ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f2316b37f04c96a17e049cbc2f3ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395534428a2f483b90acfc70f25a0920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078a306f21b1401caec2a896608e5632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcd3fafbcb7405c896be3affb7be1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358057d37d16456f9bbec47e63fa0c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe6e08ef66d4aa19556892bb5510c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a938d5d7fca04ffcbf77fb1b58cf0a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daf5e6d2ecf4293b36c5f1e7a0de9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dc985225114123b968b7c70008545b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e3aece9a7a4cbeaec5ff2527f6536b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f06176b80ac49b7ab47ada186d737b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507c1fec7b6742d3b04ea186baeddc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fa7a8f407b45b881a0ea4e98c3fbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbeb573897f4ba88123db8f9390ec1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d0bdf704064cb99fe56200f6833af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64c3287efc846ad82029d81f6b6fa41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d7fced6241480dbd6e25056d5bbc6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766336669ec0483cb208c3f3b126b22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3629307e5a454e919dc57bd75e23ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae61497f19b048bcbb719710a47922ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4812cfcfbee4519bf6d2f79be987c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3abf89582d48049ae59822005c6b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551f5f91ea5043ebb3b282ac566ccee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bed6062021447a79c2a61054741bcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5659882ddd4731a2e4a24a301ee420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f5ce929df841af8201b6361ae79cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c246bb7685444c9e83dc4d7b299ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b56d85511174b5ab194be0c81351f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b498d8d192724408b03c4a41ea5dbf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf5360327d24857947b6064d6a03f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c180c2cad2404eb168179d8b36ff19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af8151d8fa546ab93a5b0e560af4d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fac10ebb654d238b290c15cc29a2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132d2175f1594303b357e2acd6451f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a073beba789f481f97b93870abd61027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847d12ec279f4e8ab3177e4239b95672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac95e96ae5441158a49c5816f1a4a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937109be783f4faba7f75a2246d51090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11868f7b5864ef0b032bbe156572611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eea23de6b724be7974555964839cc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4862aec0e1451fb22ff97207b6d301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a07d9a13ff8445a87e97b30a06aa218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519aec5746b3415ea3f5bd94e646ff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a69aba5fa2402e980e04c7f2160293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae9bcd4e5294fc7b63ede9a9b47ca3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdc40ca373843728c4a64a5f6522adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4507512c6efc4bd7b5cc5413e77ab569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3eef61eca64aa8afb9fa2f510b6c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8675e20bd20845fdb25c83dfd64a02b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ea8a38bd474614acf00836f2150220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb45cfcb8194656b8f69044f8847765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7f64366456486dadeab113635b125d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d2e80eb55c4b4b8b2b661f6b84fdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45a2ba397704015946f2284a60e3e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46481e167a5f4926be3e7dcef07d2b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743ed4bb9ed748c6957c1bb7fd1cfab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0765b3ad5b0942888982cf3ae444401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631eb589e45340909f75aab91dd6cef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3671dc036eb6464bbb7fef4122ab37e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effb54459bdb41fd8767b6e90f00f929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f8d296ee2a47ab811060f2da97964a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b1504c0b5b41d291d47c6ac1377ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b220a3081b4658b386c48c3506e1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55efb82f659443479dffd9e11d32a356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5339b01d2e0549bfa485d4a4e1c3c7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3508227a5a146eeab395032bbf75e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df0394ce2c54391a19f3a055f6026a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d47e44221bc453b8227ecac4cca4466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ade4d3a4d59401fa61a439d19781360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ded4fdf341c42a9801cada8469dc196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2146e24b0924a9cb2aae70bf62db817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe601a0c8ca4241a8414b6dac9483cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0743caa9b494d359fe758265a710dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0fbd27dead4b938a135c3abf94c931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa56fae4e3b4807b9ed42f443f8ad62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5727a3d1a3d4f58ad988b603c23bf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd76f0cc0778452c84056c55bf335ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76adc6b33a674d4db34d4ca0507c7b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64adc46d46a244e28a1ead0fd6fac333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e32b341af944b78f43d457f52fd0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee9a9c3bfe645ac86b67d1d7b6352b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c3d8c64124a1b8d15a471625cf869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ec935ce21b46c8940947de17cbab49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1137c3238ba49eeb193b7e653fa86d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36654995976a4841b082a34a29cbf426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ddc105509143c794b13a6373a1b464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5d8f43eb054e61954749e4b6756358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc6d81e15c0419985e34e0d42dcf62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3222d5135059441cb4f20b0e15c37790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6344e5cadf974e20981700836c095435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ccdf4aa697474fb32f93e6bd738f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740bcb30f2a84330862401e745e67f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75f84c4a733472985ecb44615535636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc0b4df6d414d8baba93ffcfaba1670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3e16e14d0c4f44bd9f155680832cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e5cede6dd542edb2e8d81285d086b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f46cc870af46dca7e34d5add3e8cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70013d29c97445adbe5d04b1d6cb55b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81aafe20ac34ef8b9fe4dc48c5dab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15aaa1f202884ca7b39a8c7bda58c051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc3b9defa2d4f4da3b87fa1ff765d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd6fadf248948d79fd4649bc24e9208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe84beeb980d4c87be6b31727382d28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97a21d2a0f947e39c6a05402ed4d86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd3b03a905046aea28560eb0f24539e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b51ae0dbdbb47efb6301ace2e19399c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ada9f1b22e94862b14e69bfeb0bba72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d9d7c2b1354bce976027c03c9ad51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee9410e54f641d39c00bdbe384b32bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a69a01d0bad4a35b0119c877b9c1a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/1567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Run the main processing\n",
    "Settings.chunk_size = 1024 \n",
    "Settings.chunk_overlap = 20\n",
    "Settings.metadata_max_length = 1000  # Add metadata length limit\n",
    "index = main(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_engine(index: VectorStoreIndex):\n",
    "    \"\"\"Create a query engine with specific configurations.\"\"\"\n",
    "    return index.as_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        response_mode=\"tree_summarize\"\n",
    "    )\n",
    "\n",
    "def search_documents(query: str, index: VectorStoreIndex, \n",
    "                    filters: Dict = None) -> Dict:\n",
    "    \"\"\"Search documents with optional filters.\"\"\"\n",
    "    query_engine = create_query_engine(index)\n",
    "    response = query_engine.query(query)\n",
    "    \n",
    "    # Extract source nodes and metadata\n",
    "    sources = []\n",
    "    for node in response.source_nodes:\n",
    "        sources.append({\n",
    "            \"text\": node.text,\n",
    "            \"metadata\": node.metadata,\n",
    "            \"score\": node.score\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"sources\": sources\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing index with a sample query...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32c56bbb6d54a7fa0c77019e89cb85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 19:25:11,626 - httpx - INFO - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Query Response:\n",
      "The main topics covered in the documents include consumer goods, infrastructure, and a global overview of various asset classes across different domiciles. Additionally, there is a statement of purpose that likely outlines the objectives or intentions of the content.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "            similarity_top_k=5,\n",
    "            response_mode=\"tree_summarize\"\n",
    "        )\n",
    "        \n",
    "print(\"\\nTesting index with a sample query...\")\n",
    "response = query_engine.query(\n",
    "    \"What are the main topics covered in these documents?\"\n",
    ")\n",
    "print(\"\\nSample Query Response:\")\n",
    "print(response.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What are the main topics covered?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32c03fa12d04338aa5e5c818a1c7fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 19:29:35,927 - httpx - INFO - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The main topics covered include the current state of the active versus passive debate, the beginning of this debate, and a detailed analysis of the evolution of active and passive investing. Additionally, there is a framing of the active versus passive debate and implications for the future of asset management.\n",
      "\n",
      "Query: Show me any tables related to financial data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05d92fc3eb74a9b8c546de8bca2ccb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 19:29:37,356 - httpx - INFO - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: There are no specific tables mentioned in the provided information related to financial data. However, there are references to granular line-item details and classifications, such as the US Equity Large-Cap Blend's percentage of total at the end of 1999, which may imply the presence of detailed financial data in the document. For specific tables, further examination of the document would be necessary.\n",
      "\n",
      "Query: What images are present in the documents?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1035b0e7156a4621a406b58ae869e2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 19:29:37,984 - httpx - INFO - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The document contains an image that appears to be a line graph with approximately 2246 vertical lines and 2270 horizontal lines.\n"
     ]
    }
   ],
   "source": [
    "def format_query_response(response, query_type=\"general\"):\n",
    "    \"\"\"Format query response based on content type.\"\"\"\n",
    "    \n",
    "    if query_type == \"images\":\n",
    "        formatted_response = \"Here are the relevant images:\\n\\n\"\n",
    "        for node in response.source_nodes:\n",
    "            if node.metadata.get(\"type\") == \"image\":\n",
    "                formatted_response += (\n",
    "                    f\"## Image on page {node.metadata['page_num']}\\n\"\n",
    "                    f\"{node.metadata['markdown_link']}\\n\"\n",
    "                    f\"**Caption:** {node.metadata['caption']}\\n\\n\"\n",
    "                )\n",
    "    \n",
    "    elif query_type == \"tables\":\n",
    "        formatted_response = \"Here are the relevant tables:\\n\\n\"\n",
    "        for node in response.source_nodes:\n",
    "            if node.metadata.get(\"type\") == \"table\":\n",
    "                formatted_response += (\n",
    "                    f\"## Table from {node.metadata['source']}\\n\"\n",
    "                    f\"{node.metadata['markdown_table']}\\n\"\n",
    "                    f\"**Caption:** {node.metadata['caption']}\\n\"\n",
    "                    f\"[Download Excel]({node.metadata['excel_path']})\\n\\n\"\n",
    "                )\n",
    "    \n",
    "    else:\n",
    "        formatted_response = response.response\n",
    "    print(formatted_response)\n",
    "    return formatted_response\n",
    "\n",
    "def query_documents(query: str, index: VectorStoreIndex):\n",
    "    query_engine = index.as_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        response_mode=\"tree_summarize\"\n",
    "    )\n",
    "    \n",
    "    # Determine query type\n",
    "    query_type = \"general\"\n",
    "    if \"image\" in query.lower():\n",
    "        query_type = \"images\"\n",
    "    elif \"table\" in query.lower():\n",
    "        query_type = \"tables\"\n",
    "    \n",
    "    # Get and format response\n",
    "    response = query_engine.query(query)\n",
    "    formatted_response = format_query_response(response, query_type)\n",
    "    \n",
    "    return formatted_response\n",
    "if index:\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"What are the main topics covered?\",\n",
    "        \"Show me any tables related to financial data\",\n",
    "        \"What images are present in the documents?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        response = query_engine.query(query)\n",
    "        print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-dSPC7ywe-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
