{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from typing import List, Dict, Any, Tuple, Optional, Union\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import logging\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Document,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "\n",
    "import io\n",
    "import pymupdf as fitz\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from llama_index.core import Document, Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "import logging\n",
    "from llama_index.core import Settings, StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.readers.file import PDFReader\n",
    "from datetime import datetime\n",
    "from llama_index.core import Document, Settings, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from typing import Sequence\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import pymupdf as fitz\n",
    "import llama_index.core\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 10:15:38,159 - opentelemetry.instrumentation.instrumentor - WARNING - Attempting to instrument while already instrumented\n",
      "2024-11-04 10:15:38,166 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "2024-11-04 10:15:44,169 - sentence_transformers.SentenceTransformer - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "            embed_batch_size=10\n",
    ")\n",
    "Settings.embed_model = embed_model\n",
    "Settings.dimension = 768\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('document_processing.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Document,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.vector_stores.simple import SimpleVectorStore\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "mcd = None\n",
    "class TextBlock(BaseModel):\n",
    "    \"\"\"Text block in the report\"\"\"\n",
    "    text: str = Field(..., description=\"The text content\")\n",
    "    source: Optional[str] = Field(None, description=\"Source of the text\")\n",
    "    page_num: Optional[int] = Field(None, description=\"Page number\")\n",
    "\n",
    "class ImageBlock(BaseModel):\n",
    "    \"\"\"Image block in the report\"\"\"\n",
    "    file_path: str = Field(..., description=\"Path to the image file\")\n",
    "    caption: Optional[str] = Field(None, description=\"Image caption\")\n",
    "    source: Optional[str] = Field(None, description=\"Source of the image\")\n",
    "    page_num: Optional[int] = Field(None, description=\"Page number\")\n",
    "\n",
    "class TableBlock(BaseModel):\n",
    "    \"\"\"Table block in the report\"\"\"\n",
    "    file_path: str = Field(..., description=\"Path to the table image\")\n",
    "    excel_path: Optional[str] = Field(None, description=\"Path to Excel file\")\n",
    "    caption: Optional[str] = Field(None, description=\"Table caption\")\n",
    "    source: Optional[str] = Field(None, description=\"Source of the table\")\n",
    "    page_num: Optional[int] = Field(None, description=\"Page number\")\n",
    "\n",
    "class ReportOutput(BaseModel):\n",
    "    \"\"\"Structured output for report generation\"\"\"\n",
    "    title: str = Field(..., description=\"Report title\")\n",
    "    summary: str = Field(..., description=\"Executive summary\")\n",
    "    blocks: List[Union[TextBlock, ImageBlock, TableBlock]] = Field(\n",
    "        ..., \n",
    "        description=\"Content blocks in the report\"\n",
    "    )\n",
    "\n",
    "class RAGQueryEngine:\n",
    "    \"\"\"Enhanced RAG Query Engine with structured outputs\"\"\"\n",
    "    \n",
    "    def __init__(self, storage_dir: str = \"./storage\"):\n",
    "        self.storage_dir = Path(storage_dir)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Initialize embedding model\n",
    "        self.embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "            embed_batch_size=10\n",
    "        )\n",
    "        \n",
    "        # Initialize LLM\n",
    "        system_prompt = \"\"\"You are a report generation assistant that produces well-formatted\n",
    "        responses with text, images, and tables. Include relevant visual elements when they add value.\n",
    "        Structure your response according to the ReportOutput schema.\"\"\"\n",
    "        \n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\", api_base=\"https://models.inference.ai.azure.com\", system_prompt=system_prompt)\n",
    "        \n",
    "        # Set global models\n",
    "        Settings.embed_model = self.embed_model\n",
    "        Settings.llm = self.llm\n",
    "        \n",
    "        # Initialize storage context\n",
    "        vector_store = SimpleVectorStore()\n",
    "        self.storage_context = StorageContext.from_defaults(\n",
    "            persist_dir=str(self.storage_dir),\n",
    "            vector_store=vector_store\n",
    "        )\n",
    "\n",
    "\n",
    "    def build_index(self, documents: List[Document]):\n",
    "        \"\"\"Build or load index\"\"\"\n",
    "        try:\n",
    "            # Try to load existing index\n",
    "            if (self.storage_dir / \"index\").exists():\n",
    "                self.index = load_index_from_storage(self.storage_context)\n",
    "                self.logger.info(\"Loaded existing index\")\n",
    "            else:\n",
    "                # Build new index\n",
    "                self.index = VectorStoreIndex.from_documents(\n",
    "                    documents,\n",
    "                    storage_context=self.storage_context,\n",
    "                    show_progress=True\n",
    "                )\n",
    "                # Persist index\n",
    "                self.index.storage_context.persist()\n",
    "                self.logger.info(\"Built and persisted new index\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error building index: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    async def query(\n",
    "        self,\n",
    "        query_text: str,\n",
    "        response_mode: str = \"tree_summarize\",\n",
    "        similarity_top_k: int = 5\n",
    "            ) -> ReportOutput:\n",
    "        \"\"\"Execute structured query\"\"\"\n",
    "        try:\n",
    "            if not self.index:\n",
    "                raise ValueError(\"Index not built. Please build index first.\")\n",
    "            \n",
    "            # Create structured LLM\n",
    "            structured_llm = self.llm.as_structured_llm(output_cls=ReportOutput)\n",
    "            \n",
    "            # Configure response synthesizer\n",
    "            response_synthesizer = get_response_synthesizer(\n",
    "                response_mode=response_mode,\n",
    "                structured_answer_filtering=True\n",
    "            )\n",
    "            \n",
    "            # Create query engine with all parameters\n",
    "            query_engine = self.index.as_query_engine(\n",
    "                similarity_top_k=similarity_top_k,\n",
    "                response_synthesizer=response_synthesizer,\n",
    "                llm=structured_llm,\n",
    "                node_postprocessors=[\n",
    "                    SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Execute query\n",
    "            response = await query_engine.aquery(query_text)\n",
    "            \n",
    "            # Process and structure the response\n",
    "            return self._process_response(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error executing query: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_response(self, response) -> ReportOutput:\n",
    "        \"\"\"Process query response into structured output\"\"\"\n",
    "        blocks = []\n",
    "        \n",
    "        # Process source nodes\n",
    "        for node in response.source_nodes:\n",
    "            metadata = node.metadata\n",
    "            \n",
    "            if metadata.get(\"type\") == \"text\":\n",
    "                blocks.append(TextBlock(\n",
    "                    text=node.text,\n",
    "                    source=metadata.get(\"source\"),\n",
    "                    page_num=metadata.get(\"page_num\")\n",
    "                ))\n",
    "            \n",
    "            elif metadata.get(\"type\") == \"image\":\n",
    "                blocks.append(ImageBlock(\n",
    "                    file_path=metadata.get(\"image\"),\n",
    "                    caption=metadata.get(\"caption\"),\n",
    "                    source=metadata.get(\"source\"),\n",
    "                    page_num=metadata.get(\"page_num\")\n",
    "                ))\n",
    "            \n",
    "            elif metadata.get(\"type\") == \"table\":\n",
    "                blocks.append(TableBlock(\n",
    "                    file_path=metadata.get(\"image\"),\n",
    "                    excel_path=metadata.get(\"dataframe\"),\n",
    "                    caption=metadata.get(\"caption\"),\n",
    "                    source=metadata.get(\"source\"),\n",
    "                    page_num=metadata.get(\"page_num\")\n",
    "                ))\n",
    "        mcd = response        \n",
    "                \n",
    "        logging.info(f\"Processed response for query: {response.query}\")\n",
    "        logging.info(f\"Response: {response}\")\n",
    "        \n",
    "        return ReportOutput(\n",
    "            title=f\"Report\",\n",
    "            summary=response.response,\n",
    "            blocks=blocks\n",
    "        )\n",
    "\n",
    "    def render_report(self, report: ReportOutput):\n",
    "        \"\"\"Render the structured report\"\"\"\n",
    "        from IPython.display import display, Markdown, Image\n",
    "        \n",
    "        # Display title and summary\n",
    "        display(Markdown(f\"# {report.title}\"))\n",
    "        display(Markdown(f\"## Executive Summary\\n{report.summary}\\n\"))\n",
    "        \n",
    "        # Display content blocks\n",
    "        for block in report.blocks:\n",
    "            if isinstance(block, TextBlock):\n",
    "                display(Markdown(f\"### Content from {block.source} (Page {block.page_num})\\n{block.text}\\n\"))\n",
    "                \n",
    "            elif isinstance(block, ImageBlock):\n",
    "                display(Markdown(f\"### Image from {block.source} (Page {block.page_num})\"))\n",
    "                display(Image(filename=block.file_path))\n",
    "                if block.caption:\n",
    "                    display(Markdown(f\"*{block.caption}*\\n\"))\n",
    "                    \n",
    "            elif isinstance(block, TableBlock):\n",
    "                display(Markdown(f\"### Table from {block.source} (Page {block.page_num})\"))\n",
    "                display(Image(filename=block.file_path))\n",
    "                if block.caption:\n",
    "                    display(Markdown(f\"*{block.caption}*\\n\"))\n",
    "                display(Markdown(f\"[Download Excel]({block.excel_path})\\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field\n",
    "import fitz\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ContentBlock(BaseModel):\n",
    "    \"\"\"Base content block\"\"\"\n",
    "    content_type: str\n",
    "    page_num: int\n",
    "    metadata: Dict\n",
    "\n",
    "class TextBlock(ContentBlock):\n",
    "    \"\"\"Text block for output\"\"\"\n",
    "    text: str = Field(..., description=\"The text content\")\n",
    "\n",
    "class ImageBlock(ContentBlock):\n",
    "    \"\"\"Image block for output\"\"\"\n",
    "    image_path: str = Field(..., description=\"Path to image file\")\n",
    "    caption: Optional[str] = Field(None, description=\"Image caption\")\n",
    "\n",
    "class ReportOutput(BaseModel):\n",
    "    \"\"\"Structured report output\"\"\"\n",
    "    title: str = Field(..., description=\"Report title\")\n",
    "    summary: str = Field(..., description=\"Executive summary\")\n",
    "    blocks: List[Union[TextBlock, ImageBlock]] = Field(\n",
    "        ..., description=\"Content blocks\"\n",
    "    )\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Render report with text and images\"\"\"\n",
    "        display(Markdown(f\"# {self.title}\"))\n",
    "        display(Markdown(f\"## Executive Summary\\n{self.summary}\"))\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            if isinstance(block, TextBlock):\n",
    "                display(Markdown(block.text))\n",
    "            else:\n",
    "                display(Image(filename=block.image_path))\n",
    "                if block.caption:\n",
    "                    display(Markdown(f\"*{block.caption}*\"))\n",
    "\n",
    "class DocumentProcessor:\n",
    "    \"\"\"Document processing with PyMuPDF\"\"\"\n",
    "    \n",
    "    def __init__(self, storage_dir: str = \"./storage\"):\n",
    "        self.storage_dir = Path(storage_dir)\n",
    "        self.storage_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        self.image_dir = self.storage_dir / \"images\"\n",
    "        self.image_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.table_dir = self.storage_dir / \"tables\"\n",
    "        self.table_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.cache_dir = self.storage_dir / \"cache\"\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def process_document(self, file_path: str) -> List[Document]:\n",
    "        \"\"\"Process document and return list of Documents\"\"\"\n",
    "        cache_path = self.cache_dir / f\"{Path(file_path).stem}_processed.pkl\"\n",
    "        \n",
    "        if cache_path.exists():\n",
    "            self.logger.info(f\"Loading cached processing results: {cache_path}\")\n",
    "            import pickle\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        \n",
    "        try:\n",
    "            doc = fitz.open(file_path)\n",
    "            all_documents = []\n",
    "            \n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc[page_num]\n",
    "                page_documents = self._process_page(page, page_num, file_path)\n",
    "                all_documents.extend(page_documents)\n",
    "            \n",
    "            doc.close()\n",
    "            \n",
    "            # Cache results\n",
    "            with open(cache_path, 'wb') as f:\n",
    "                import pickle\n",
    "                pickle.dump(all_documents, f)\n",
    "            \n",
    "            return all_documents\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing document: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_page(self, page, page_num: int, source_file: str) -> List[Document]:\n",
    "        \"\"\"Process a single page and return list of Documents\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        try:\n",
    "            # Extract text blocks\n",
    "            text_blocks = self._extract_text_blocks(page, page_num)\n",
    "            for idx, block in enumerate(text_blocks):\n",
    "                doc = Document(\n",
    "                    text=block[\"text\"],\n",
    "                    metadata={\n",
    "                        \"source\": f\"{Path(source_file).stem}-page{page_num}-text{idx}\",\n",
    "                        \"page_num\": page_num,\n",
    "                        \"type\": \"text\",\n",
    "                        \"bbox\": block[\"bbox\"],\n",
    "                        \"id_\": f\"{Path(source_file).stem}-page{page_num}-text{idx}\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            \n",
    "            # Extract images\n",
    "            images = self._extract_images(page, page_num, source_file)\n",
    "            for idx, image in enumerate(images):\n",
    "                doc = Document(\n",
    "                    text=f\"Image from page {page_num}\",\n",
    "                    metadata={\n",
    "                        \"source\": f\"{Path(source_file).stem}-page{page_num}-image{idx}\",\n",
    "                        \"page_num\": page_num,\n",
    "                        \"type\": \"image\",\n",
    "                        \"image_path\": image[\"image_path\"],\n",
    "                        \"bbox\": image[\"bbox\"],\n",
    "                        \"id_\": f\"{Path(source_file).stem}-page{page_num}-image{idx}\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            \n",
    "            # Extract tables\n",
    "            tables = self._extract_tables(page, page_num, source_file)\n",
    "            for idx, table in enumerate(tables):\n",
    "                doc = Document(\n",
    "                    text=f\"Table from page {page_num}\",\n",
    "                    metadata={\n",
    "                        \"source\": f\"{Path(source_file).stem}-page{page_num}-table{idx}\",\n",
    "                        \"page_num\": page_num,\n",
    "                        \"type\": \"table\",\n",
    "                        \"table_path\": table[\"table_path\"],\n",
    "                        \"excel_path\": table[\"excel_path\"],\n",
    "                        \"bbox\": table[\"bbox\"],   \n",
    "                        \"id_\": f\"{Path(source_file).stem}-page{page_num}-table{idx}\"                     \n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            \n",
    "            return documents\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing page {page_num}: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _extract_text_blocks(self, page, page_num: int) -> List[Dict]:\n",
    "        \"\"\"Extract text blocks from page\"\"\"\n",
    "        blocks = []\n",
    "        for block in page.get_text(\"blocks\"):\n",
    "            if block[6] == 0:  # Text block\n",
    "                blocks.append({\n",
    "                    \"text\": block[4],\n",
    "                    \"bbox\": {\n",
    "                        \"x0\": block[0],\n",
    "                        \"y0\": block[1],\n",
    "                        \"x1\": block[2],\n",
    "                        \"y1\": block[3]\n",
    "                    },\n",
    "                    \"page_num\": page_num\n",
    "                })\n",
    "        return blocks\n",
    "    \n",
    "    def _extract_images(self, page, page_num: int, source_file: str) -> List[Dict]:\n",
    "        \"\"\"Extract images from page\"\"\"\n",
    "        images = []\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            try:\n",
    "                xref = img[0]\n",
    "                base_image = page.parent.extract_image(xref)\n",
    "                \n",
    "                if base_image:\n",
    "                    image_path = self.image_dir / f\"{Path(source_file).stem}_page{page_num}_img{img_index}.png\"\n",
    "                    with open(image_path, \"wb\") as f:\n",
    "                        f.write(base_image[\"image\"])\n",
    "                    \n",
    "                    images.append(Document({\n",
    "                        \"image_path\": str(image_path),\n",
    "                        \"bbox\": img[1],\n",
    "                        \"page_num\": page_num,\n",
    "                        \"id\": img_index\n",
    "                    }))\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error extracting image: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        return images\n",
    "    \n",
    "    def _extract_tables(self, page, page_num: int, source_file: str) -> List[Dict]:\n",
    "        \"\"\"Extract tables from page\"\"\"\n",
    "        tables = []\n",
    "        try:\n",
    "            found_tables = page.find_tables(\n",
    "                horizontal_strategy=\"lines_strict\",\n",
    "                vertical_strategy=\"lines_strict\"\n",
    "            )\n",
    "            \n",
    "            for table_idx, table in enumerate(found_tables):\n",
    "                try:\n",
    "                    if not table.header.external:\n",
    "                        # Convert to pandas DataFrame\n",
    "                        pandas_df = table.to_pandas()\n",
    "                        \n",
    "                        # Save table as Excel\n",
    "                        excel_path = self.table_dir / f\"{Path(source_file).stem}_page{page_num}_table{table_idx}.xlsx\"\n",
    "                        pandas_df.to_excel(str(excel_path))\n",
    "                        \n",
    "                        # Create image of table area\n",
    "                        table_bbox = fitz.Rect(table.bbox)\n",
    "                        table_pix = page.get_pixmap(clip=table_bbox)\n",
    "                        image_path = self.table_dir / f\"{Path(source_file).stem}_page{page_num}_table{table_idx}.png\"\n",
    "                        table_pix.save(str(image_path))\n",
    "                        \n",
    "                        tables.append(Document({\n",
    "                            \"table_path\": str(image_path),\n",
    "                            \"excel_path\": str(excel_path),\n",
    "                            \"bbox\": table.bbox,\n",
    "                            \"columns\": list(pandas_df.columns),\n",
    "                            \"id_\": table_idx,\n",
    "                        }))\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Error processing table {table_idx} on page {page_num}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Error extracting tables from page {page_num}: {str(e)}\")\n",
    "            \n",
    "        return tables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:58:02.270351Z",
     "start_time": "2024-11-04T20:57:26.761538Z"
    }
   },
   "source": [
    "import hashlib\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import io\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional, Union, Sequence\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import llama_index\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pymupdf as fitz\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.response_synthesizers.type import ResponseMode\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Document,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "            embed_batch_size=10\n",
    ")\n",
    "Settings.embed_model = embed_model\n",
    "Settings.dimension = 768\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('document_processing.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class TextBlock(BaseModel):\n",
    "    \"\"\"Text block in the report\"\"\"\n",
    "    content_type: str = Field(\"text\", description=\"Type of content block\")  # Set default value\n",
    "    text: str = Field(..., description=\"The text content\")\n",
    "    source: Optional[str] = Field(None, description=\"Source of the text\")\n",
    "    page_num: Optional[int] = Field(None, description=\"Page number\")\n",
    "    metadata: Optional[Dict] = Field(None, description=\"Additional metadata\")\n",
    "\n",
    "\n",
    "class ImageBlock():\n",
    "    \"\"\"Image block in the report\"\"\"\n",
    "    content_type: str = Field(\"image\", description=\"Type of content block\")\n",
    "    file_path: str = Field(..., description=\"Path to the image file\")\n",
    "    caption: Optional[str] = Field(None, description=\"Image caption\")\n",
    "    source: Optional[str] = Field(None, description=\"Source of the image\")\n",
    "    page_num: Optional[int] = Field(None, description=\"Page number\")\n",
    "    metadata: Optional[Dict] = Field(None, description=\"Additional metadata\")\n",
    "\n",
    "\n",
    "class TableBlock():\n",
    "    \"\"\"Table block in the report\"\"\"\n",
    "    content_type: str = Field(\"table\", description=\"Type of content block\")\n",
    "    file_path: str = Field(..., description=\"Path to the table image\")\n",
    "    excel_path: Optional[str] = Field(None, description=\"Path to Excel file\")\n",
    "    caption: Optional[str] = Field(None, description=\"Table caption\")\n",
    "    source: Optional[str] = Field(None, description=\"Source of the table\")\n",
    "    page_num: Optional[int] = Field(None, description=\"Page number\")\n",
    "    metadata: Optional[Dict] = Field(None, description=\"Additional metadata\")\n",
    "\n",
    "\n",
    "class ReportOutput():\n",
    "    \"\"\"Structured output for report generation\"\"\"\n",
    "    title: str = Field(..., description=\"Report title\")\n",
    "    summary: str = Field(..., description=\"Executive summary\")\n",
    "    blocks: List[Union[TextBlock, ImageBlock, TableBlock]] = Field(\n",
    "        ...,\n",
    "        description=\"Content blocks in the report\"\n",
    "    )\n",
    "\n",
    "\n",
    "def initialize_vector_store(index_name: str = \"document-store\") -> PineconeVectorStore:\n",
    "    \"\"\"Initialize Pinecone vector store with the new client.\"\"\"\n",
    "\n",
    "    # Initialize Pinecone client\n",
    "    pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "    # Check if index exists, if not create it\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=768,  # OpenAI embedding dimension\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Initialize vector store\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index_name=index_name,\n",
    "        environment=os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
    "    )\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field\n",
    "import fitz\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ContentBlock(BaseModel):\n",
    "    \"\"\"Base content block\"\"\"\n",
    "    content_type: str\n",
    "    page_num: int\n",
    "    metadata: Dict\n",
    "\n",
    "\n",
    "class TextBlock(ContentBlock):\n",
    "    \"\"\"Text block for output\"\"\"\n",
    "    text: str = Field(..., description=\"The text content\")\n",
    "\n",
    "\n",
    "class ImageBlock(ContentBlock):\n",
    "    \"\"\"Image block for output\"\"\"\n",
    "    image_path: str = Field(..., description=\"Path to image file\")\n",
    "    caption: Optional[str] = Field(None, description=\"Image caption\")\n",
    "\n",
    "\n",
    "class ReportOutput(BaseModel):\n",
    "    \"\"\"Structured report output\"\"\"\n",
    "    title: str = Field(..., description=\"Report title\")\n",
    "    summary: str = Field(..., description=\"Executive summary\")\n",
    "    blocks: List[Union[TextBlock, ImageBlock]] = Field(\n",
    "        ..., description=\"Content blocks\"\n",
    "    )\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Render report with text and images\"\"\"\n",
    "        display(Markdown(f\"# {self.title}\"))\n",
    "        display(Markdown(f\"## Executive Summary\\n{self.summary}\"))\n",
    "\n",
    "        for block in self.blocks:\n",
    "            if isinstance(block, TextBlock):\n",
    "                display(Markdown(block.text))\n",
    "            else:\n",
    "                display(Image(filename=block.image_path))\n",
    "                if block.caption:\n",
    "                    display(Markdown(f\"*{block.caption}*\"))\n",
    "\n",
    "\n",
    "class DocumentProcessor:\n",
    "    \"\"\"Document processing with PyMuPDF\"\"\"\n",
    "\n",
    "    def __init__(self, storage_dir: str = \"./storage\"):\n",
    "        self.storage_dir = Path(storage_dir)\n",
    "        self.storage_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Create subdirectories\n",
    "        self.image_dir = self.storage_dir / \"images\"\n",
    "        self.image_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        self.table_dir = self.storage_dir / \"tables\"\n",
    "        self.table_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        self.cache_dir = self.storage_dir / \"cache\"\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def process_document(self, file_path: str) -> List[Document]:\n",
    "        \"\"\"Process document and return list of Documents\"\"\"\n",
    "        cache_path = self.cache_dir / f\"{Path(file_path).stem}_processed.pkl\"\n",
    "\n",
    "        if cache_path.exists():\n",
    "            self.logger.info(f\"Loading cached processing results: {cache_path}\")\n",
    "            import pickle\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "\n",
    "        try:\n",
    "            doc = fitz.open(file_path)\n",
    "            all_documents = []\n",
    "\n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc[page_num]\n",
    "                page_documents = self._process_page(page, page_num, file_path)\n",
    "                all_documents.extend(page_documents)\n",
    "\n",
    "            doc.close()\n",
    "\n",
    "            # Cache results\n",
    "            with open(cache_path, 'wb') as f:\n",
    "                import pickle\n",
    "                pickle.dump(all_documents, f)\n",
    "\n",
    "            return all_documents\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing document: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_page(self, page, page_num: int, source_file: str) -> List[Document]:\n",
    "        \"\"\"Process a single page and return list of Documents\"\"\"\n",
    "        documents = []\n",
    "\n",
    "        try:\n",
    "            # Extract text blocks\n",
    "            text_blocks = self._extract_text_blocks(page, page_num)\n",
    "            for idx, block in enumerate(text_blocks):\n",
    "                bboxstr = f\"{block['bbox']['x0']},{block['bbox']['y0']},{block['bbox']['x1']},{block['bbox']['y1']}\"\n",
    "                doc = Document(\n",
    "                    text=block[\"text\"],\n",
    "                    metadata={\n",
    "                        \"source\": f\"{Path(source_file).stem}-page{page_num}-text{idx}\",\n",
    "                        \"page_num\": page_num,\n",
    "                        \"type\": \"text\",\n",
    "                        \"bbox\": bboxstr,\n",
    "                        \"id_\": f\"{Path(source_file).stem}-page{page_num}-text{idx}\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "\n",
    "            # Extract images\n",
    "            images = self._extract_images(page, page_num, source_file)\n",
    "            for idx, image in enumerate(images):\n",
    "                bbox = image[\"bbox\"]\n",
    "                bboxstr = f\"{bbox['x1']},{bbox['y1']},{bbox['x2']},{bbox['y2']}\"\n",
    "                doc = Document(\n",
    "                    text=f\"Image from page {page_num}\",\n",
    "                    metadata={\n",
    "                        \"source\": f\"{Path(source_file).stem}-page{page_num}-image{idx}\",\n",
    "                        \"page_num\": page_num,\n",
    "                        \"type\": \"image\",\n",
    "                        \"image_path\": image[\"image_path\"],\n",
    "                        \"bbox\": bboxstr,\n",
    "                        \"id_\": f\"{Path(source_file).stem}-page{page_num}-image{idx}\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "\n",
    "            # Extract tables\n",
    "            tables = self._extract_tables(page, page_num, source_file)\n",
    "            for idx, table in enumerate(tables):\n",
    "                bboxstr = f\"{table['bbox'].x1},{table['bbox'].y1},{table['bbox'].x2},{table['bbox'].y2}\"\n",
    "\n",
    "                doc = Document(\n",
    "                    text=f\"Table from page {page_num}\",\n",
    "                    metadata={\n",
    "                        \"source\": f\"{Path(source_file).stem}-page{page_num}-table{idx}\",\n",
    "                        \"page_num\": page_num,\n",
    "                        \"type\": \"table\",\n",
    "                        \"table_path\": table[\"table_path\"],\n",
    "                        \"excel_path\": table[\"excel_path\"],\n",
    "                        \"bbox\": bboxstr,\n",
    "                        \"id_\": f\"{Path(source_file).stem}-page{page_num}-table{idx}\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "\n",
    "            return documents\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing page {page_num}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _extract_text_blocks(self, page, page_num: int) -> List[Dict]:\n",
    "        \"\"\"Extract text blocks from page\"\"\"\n",
    "        blocks = []\n",
    "        for block in page.get_text(\"blocks\"):\n",
    "            if block[6] == 0:  # Text block\n",
    "                blocks.append({\n",
    "                    \"text\": block[4],\n",
    "                    \"bbox\": {\n",
    "                        \"x0\": block[0],\n",
    "                        \"y0\": block[1],\n",
    "                        \"x1\": block[2],\n",
    "                        \"y1\": block[3]\n",
    "                    },\n",
    "                    \"page_num\": page_num\n",
    "                })\n",
    "        return blocks\n",
    "\n",
    "    def _extract_images(self, page, page_num: int, source_file: str) -> List[Dict]:\n",
    "        \"\"\"Extract images from page\"\"\"\n",
    "        images = []\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            try:\n",
    "                xref = img[0]\n",
    "                base_image = page.parent.extract_image(xref)\n",
    "\n",
    "                if base_image:\n",
    "                    image_path = self.image_dir / f\"{Path(source_file).stem}_page{page_num}_img{img_index}.png\"\n",
    "                    with open(image_path, \"wb\") as f:\n",
    "                        f.write(base_image[\"image\"])\n",
    "                    bboxstr = f\"{img[1].x0},{img[1].y0},{img[1].x1},{img[1].y1}\"\n",
    "                    images.append(Document({\n",
    "                        \"image_path\": str(image_path),\n",
    "                        \"bbox\": bboxstr,\n",
    "                        \"page_num\": page_num,\n",
    "                        \"id\": img_index\n",
    "                    }))\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error extracting image: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return images\n",
    "\n",
    "    def _extract_tables(self, page, page_num: int, source_file: str) -> List[Dict]:\n",
    "        \"\"\"Extract tables from page\"\"\"\n",
    "        tables = []\n",
    "        try:\n",
    "            found_tables = page.find_tables(\n",
    "                horizontal_strategy=\"lines_strict\",\n",
    "                vertical_strategy=\"lines_strict\"\n",
    "            )\n",
    "\n",
    "            for table_idx, table in enumerate(found_tables):\n",
    "                try:\n",
    "                    if not table.header.external:\n",
    "                        # Convert to pandas DataFrame\n",
    "                        pandas_df = table.to_pandas()\n",
    "\n",
    "                        # Save table as Excel\n",
    "                        excel_path = self.table_dir / f\"{Path(source_file).stem}_page{page_num}_table{table_idx}.xlsx\"\n",
    "                        pandas_df.to_excel(str(excel_path))\n",
    "\n",
    "                        # Create image of table area\n",
    "                        table_bbox = fitz.Rect(table.bbox)\n",
    "                        table_pix = page.get_pixmap(clip=table_bbox)\n",
    "                        image_path = self.table_dir / f\"{Path(source_file).stem}_page{page_num}_table{table_idx}.png\"\n",
    "                        table_pix.save(str(image_path))\n",
    "                        bboxstr = f\"{table.bbox.x0},{table.bbox.y0},{table.bbox.x1},{table.bbox.y1}\"\n",
    "                        tables.append(Document({\n",
    "                            \"table_path\": str(image_path),\n",
    "                            \"excel_path\": str(excel_path),\n",
    "                            \"bbox\": bboxstr,\n",
    "                            \"columns\": list(pandas_df.columns),\n",
    "                            \"id_\": table_idx,\n",
    "                        }))\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Error processing table {table_idx} on page {page_num}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Error extracting tables from page {page_num}: {str(e)}\")\n",
    "\n",
    "        return tables\n",
    "\n",
    "class RAGQueryEngine:\n",
    "    \"\"\"Enhanced RAG Query Engine with Pinecone vector store\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            storage_dir: str = \"./storage\",\n",
    "            pinecone_api_key: str = os.getenv(\"PINECONE_API_KEY\"),\n",
    "            pinecone_environment: str = \"gcp-starter\",\n",
    "            index_name: str = \"rag-index\"\n",
    "    ):\n",
    "        self.storage_dir = Path(storage_dir)\n",
    "        self.cache_dir = self.storage_dir / \"cache\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Create directories\n",
    "        self.storage_dir.mkdir(exist_ok=True)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Initialize Pinecone\n",
    "        self.pc = Pinecone(api_key=pinecone_api_key)\n",
    "        self.index_name = index_name\n",
    "\n",
    "        # Initialize embedding model\n",
    "        self.embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "            embed_batch_size=10\n",
    "        )\n",
    "\n",
    "        # Initialize LLM\n",
    "        system_prompt = \"\"\"You are a report generation assistant that produces well-formatted\n",
    "        responses with text, images, and tables. Include relevant visual elements when they add value.\n",
    "        Structure your response according to the ReportOutput schema.\"\"\"\n",
    "\n",
    "        self.llm = OpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            api_base=\"https://models.inference.ai.azure.com\",\n",
    "            system_prompt=system_prompt\n",
    "        )\n",
    "\n",
    "        # Set global models\n",
    "        Settings.embed_model = self.embed_model\n",
    "        Settings.llm = self.llm\n",
    "\n",
    "        # Initialize or load Pinecone index\n",
    "        self._initialize_vector_store()\n",
    "\n",
    "    def _initialize_vector_store(self):\n",
    "        \"\"\"Initialize or load Pinecone vector store\"\"\"\n",
    "        try:\n",
    "            # Check if index exists\n",
    "            existing_indexes = self.pc.list_indexes().names()\n",
    "\n",
    "            if self.index_name not in existing_indexes:\n",
    "                # Create new index\n",
    "                self.pc.create_index(\n",
    "                    name=self.index_name,\n",
    "                    dimension=768,  # BGE-base dimension\n",
    "                    metric=\"cosine\",\n",
    "                    spec=ServerlessSpec(\n",
    "                        cloud=\"aws\",\n",
    "                        region=\"us-east-1\"\n",
    "                    )\n",
    "                )\n",
    "                self.logger.info(f\"Created new Pinecone index: {self.index_name}\")\n",
    "\n",
    "            # Connect to index\n",
    "            self.pinecone_index = self.pc.Index(self.index_name)\n",
    "\n",
    "            # Initialize vector store\n",
    "            self.vector_store = PineconeVectorStore(\n",
    "                pinecone_index=self.pinecone_index,\n",
    "                metadata_filters={\"type\": [\"text\", \"image\", \"table\"]}\n",
    "            )\n",
    "\n",
    "\n",
    "            # Initialize storage context\n",
    "            self.storage_context = StorageContext.from_defaults(\n",
    "                vector_store=self.vector_store\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing vector store: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _get_cache_key(self, documents: List[Document]) -> str:\n",
    "        \"\"\"Generate cache key for documents\"\"\"\n",
    "        content_hash = hashlib.md5()\n",
    "        for doc in sorted(documents, key=lambda x: x.id_):\n",
    "            content_hash.update(str(doc.hash).encode())\n",
    "        return content_hash.hexdigest()\n",
    "\n",
    "    def build_index(self, documents: List[Document]):\n",
    "        \"\"\"Build or load index with caching\"\"\"\n",
    "        try:\n",
    "            # Generate cache key\n",
    "            cache_key = self._get_cache_key(documents)\n",
    "            cache_path = self.cache_dir / f\"index_cache_{cache_key}.pkl\"\n",
    "\n",
    "            # Check cache\n",
    "            if cache_path.exists():\n",
    "                self.logger.info(\"Loading index from cache...\")\n",
    "                with open(cache_path, 'rb') as f:\n",
    "                    cached_data = pickle.load(f)\n",
    "\n",
    "                # Verify if documents are already in Pinecone\n",
    "                stats = self.pinecone_index.describe_index_stats()\n",
    "                if stats.total_vector_count == len(documents):\n",
    "                    self.logger.info(\"Documents already indexed in Pinecone\")\n",
    "                    return\n",
    "\n",
    "            # Build new index\n",
    "            self.logger.info(\"Building new index...\")\n",
    "\n",
    "            # Prepare documents for upsert\n",
    "            vectors_to_upsert = []\n",
    "            for doc in documents:\n",
    "                # Generate embedding\n",
    "                embedding = self.embed_model.get_text_embedding(doc.text)\n",
    "\n",
    "                # Prepare vector data\n",
    "                vector_data = {\n",
    "                    \"id\": doc.id_,\n",
    "                    \"values\": embedding,\n",
    "                    \"metadata\": {\n",
    "                        **doc.metadata,\n",
    "                        \"text\": doc.text,\n",
    "                        \"doc_hash\": doc.hash\n",
    "                    }\n",
    "                }\n",
    "                vectors_to_upsert.append(vector_data)\n",
    "\n",
    "            # Upsert in batches\n",
    "            batch_size = 100\n",
    "            for i in range(0, len(vectors_to_upsert), batch_size):\n",
    "                batch = vectors_to_upsert[i:i + batch_size]\n",
    "                self.pinecone_index.upsert(vectors=batch)\n",
    "\n",
    "            # Cache the index metadata\n",
    "            with open(cache_path, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'doc_hashes': [doc.hash for doc in documents],\n",
    "                    'index_name': self.index_name\n",
    "                }, f)\n",
    "\n",
    "            self.logger.info(f\"Successfully indexed {len(documents)} documents\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error building index: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    async def query(\n",
    "            self,\n",
    "            query_text: str,\n",
    "            response_mode: str = \"tree_summarize\",\n",
    "            similarity_top_k: int = 5\n",
    "    ) -> ReportOutput:\n",
    "        \"\"\"Execute structured query\"\"\"\n",
    "        try:\n",
    "            # Create structured LLM\n",
    "            structured_llm = self.llm.as_structured_llm(output_cls=ReportOutput)\n",
    "\n",
    "            # Configure response synthesizer\n",
    "            response_synthesizer = get_response_synthesizer(\n",
    "                response_mode=ResponseMode.TREE_SUMMARIZE,\n",
    "                structured_answer_filtering=True\n",
    "            )\n",
    "            index = VectorStoreIndex.from_vector_store(vector_store=self.vector_store, show_progress=True)\n",
    "            # Create query engine\n",
    "            query_engine = index.as_query_engine(\n",
    "                similarity_top_k=similarity_top_k,\n",
    "                response_synthesizer=response_synthesizer,\n",
    "                llm=structured_llm,\n",
    "                node_postprocessors=[\n",
    "                    SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Execute query\n",
    "            response = await query_engine.aquery(query_text)\n",
    "\n",
    "            # Process and structure the response\n",
    "            return self._process_response(response)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error executing query: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _process_response(self, response) -> ReportOutput:\n",
    "        \"\"\"Process query response into structured output\"\"\"\n",
    "        blocks = []\n",
    "\n",
    "        # Process source nodes\n",
    "        for node in response.source_nodes:\n",
    "            metadata = node.metadata\n",
    "\n",
    "            if metadata.get(\"type\") == \"text\":\n",
    "                blocks.append(TextBlock(\n",
    "                    text=node.text,\n",
    "                    source=metadata.get(\"source\"),\n",
    "                    page_num=metadata.get(\"page_num\"),\n",
    "                    metadata=metadata,\n",
    "                    content_type=\"text\"\n",
    "                ))\n",
    "\n",
    "            elif metadata.get(\"type\") == \"image\":\n",
    "                blocks.append(ImageBlock(\n",
    "                    file_path=metadata.get(\"image\"),\n",
    "                    caption=metadata.get(\"caption\"),\n",
    "                    source=metadata.get(\"source\"),\n",
    "                    page_num=metadata.get(\"page_num\"),\n",
    "                    metadata=metadata,\n",
    "                    content_type=\"image\"\n",
    "\n",
    "                ))\n",
    "\n",
    "            elif metadata.get(\"type\") == \"table\":\n",
    "                blocks.append(TableBlock(\n",
    "                    file_path=metadata.get(\"image\"),\n",
    "                    excel_path=metadata.get(\"dataframe\"),\n",
    "                    caption=metadata.get(\"caption\"),\n",
    "                    source=metadata.get(\"source\"),\n",
    "                    page_num=metadata.get(\"page_num\"),\n",
    "                    content_type=\"table\",\n",
    "                    metadata=metadata\n",
    "                ))\n",
    "        mcd = response\n",
    "        # if empty response throw error\n",
    "\n",
    "        logging.info(f\"Response: {response}\")\n",
    "        return ReportOutput(\n",
    "            title=f\"Report\",\n",
    "            summary=response.response,\n",
    "            blocks=blocks\n",
    "        )\n",
    "\n",
    "    def render_report(self, report: ReportOutput):\n",
    "        \"\"\"Render the structured report\"\"\"\n",
    "        from IPython.display import display, Markdown, Image\n",
    "\n",
    "        # Display title and summary\n",
    "        display(Markdown(f\"# {report.title}\"))\n",
    "        display(Markdown(f\"## Executive Summary\\n{report.summary}\\n\"))\n",
    "\n",
    "        # Display content blocks\n",
    "        for block in report.blocks:\n",
    "            if isinstance(block, TextBlock):\n",
    "                display(Markdown(f\"### Content from {block.metadata[\"source\"]} (Page {block.page_num})\\n{block.text}\\n\"))\n",
    "\n",
    "            elif isinstance(block, ImageBlock):\n",
    "                display(Markdown(f\"### Image from {block.metadata[\"source\"]} (Page {block.page_num})\"))\n",
    "                display(Image(filename=block.file_path))\n",
    "                if block.caption:\n",
    "                    display(Markdown(f\"*{block.caption}*\\n\"))\n",
    "\n",
    "            elif isinstance(block, TableBlock):\n",
    "                display(Markdown(f\"### Table from {block.metadata[\"source\"]} (Page {block.page_num})\"))\n",
    "                display(Image(filename=block.file_path))\n",
    "                if block.caption:\n",
    "                    display(Markdown(f\"*{block.caption}*\\n\"))\n",
    "                display(Markdown(f\"[Download Excel]({block.excel_path})\\n\"))\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Initialize query engine\n",
    "    query_engine = RAGQueryEngine()\n",
    "    processor = DocumentProcessor()\n",
    "    # Load and process documents\n",
    "    documents = processor.process_document(\n",
    "        \"/Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf/sample.pdf\")\n",
    "\n",
    "    # Build index\n",
    "    query_engine.build_index(documents)\n",
    "\n",
    "    # Execute query\n",
    "    # query = \"Summarize the key financial metrics and include relevant charts\"\n",
    "    query = \"What is this assignment about?\"\n",
    "    report = await query_engine.query(\n",
    "        query,\n",
    "        response_mode=\"tree_summarize\",\n",
    "        similarity_top_k=10\n",
    "    )\n",
    "\n",
    "    # Render report\n",
    "    query_engine.render_report(report)\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (needed for Jupyter)\n",
    "nest_asyncio.apply()\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 15:57:39,764 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/saisuryamadhav/Library/Caches/pypoetry/virtualenvs/backend-dSPC7ywe-py3.12/lib/python3.12/site-packages/pinecone_plugins'])\n",
      "2024-11-04 15:57:39,767 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2024-11-04 15:57:39,798 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n",
      "2024-11-04 15:57:39,800 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "2024-11-04 15:57:40,817 - sentence_transformers.SentenceTransformer - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2024-11-04 15:57:42,466 - __main__ - INFO - Building new index...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2bd91d7541540aa9ebed598e0380a2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7434039cd6bd462fa2dc5cc27e459115"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f1e80c74da74bdaadd8cec2fd492ab5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8aa2d70a7ebf4e6cba5782102a83fc43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fde0000966a45c789d432f2b99c4b21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79219f4028d14667b0f5b60c87dde647"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43997061c6f4457183d2e1671b04cc8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e579ca2eb174c3c99ad6e8c0623bf90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03629278eca04d95942f282bd91898b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1cb46115120453586b5c768b2494c04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18e80ec68d7b4b91adf9c48918918b9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b0c50b93744499498815cd2c269e27c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3566705206bd42fab56a5f1e95fd3475"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec1f53664b2c4bcfb444bd14c1bd3455"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "508d2ae737e4415e8c2eedcdbbd2611f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f0a0993a5ec424f911af61c8653aef2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10dc8e3d14664f178496755ed974dcc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5dbc3a431e84f3d9c687e50ae35a90a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6252f3f99864fcaae0d1ac45ff90cb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26abab64dbbb471e90d89c08501a4380"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "702acad19efe4540a0aaf917aecdef1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b9e4f8e5da34299bfa22f164ee2a9ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "435806c6ee20488f974082ed820e8186"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebd8663f2dcd4cab99f24f9cce869ea1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d6ae7a0747d45dc9ad502d84a61f6ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c7f80f7a0284bfb8f96d07c2a4d4d1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6aa3bcf4361d450da8e9438c0e56d761"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96f9097c3bfc4dd9abeba0ec4fba65d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e56fbb572d744959d2c28287aec4cbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "065aaea6554c4c0d94443ee898e31642"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1861400a76fa4b52ac2ec3a754a64936"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1813c9056f45426f829e23d1839ea932"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60d85bd3fb1a4044b9e9274f5b3b1ef1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f244bd0aade74ae79ba3ad643990dd8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25f9641b2f39436fb88570c4c08af964"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0894228c869249c497396d4363db8a2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7599a47a3e3146618c7a2367ac918133"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "930e78595afe420e820debc02bc10417"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b23df719dc9416f97d43f9fe304363d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68c006e17d79413fbde9721a82ad5c49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1aa97636ac14061a72557d7aa8359a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c42be5e3476458bbd6d858d478d30cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99c68a675da24966a43b4ab865342dab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8f374f113eb460aba1aa4659503685b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d7b9ba349b24cfa8de7f13c94dc2930"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de6e6a9a0cdc4f23b6a57d2ae77c2588"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cf4f65d20054aeeb7d5e552d5e41580"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e40783e8cd74edaba7d37825a3158df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfe1e6cd487f4eddab627e826d549c7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0d4351a27b7431dbe01da34d3f9b51e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "950d3a5f8d6a4ab49506d3128f4622ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5485285aaa184a19865103f448132f83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a593e7ba8b64f6081ea9f2343a46ec8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17158963523840f6bd270b3a2cd93e47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d7d795eb16f4005ada655ba77536df1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c338e0b497b54fa8abf2d2f6322a6fb2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebda815625604dfaa72ff9843cd3a66f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38504be328594eff87399e06ed774716"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8508004a97834ae38d9413a2b6002b9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33040a236fca46c4a8edfc21da51b9ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b774e401d26c43d9af35c4d85baa67c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 15:57:59,544 - __main__ - INFO - Successfully indexed 61 documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23ad4aef0f2c4fb69e6ce50163b98763"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 15:58:01,899 - httpx - INFO - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-04 15:58:02,262 - root - INFO - Response: # Assignment Overview Report\n",
      "\n",
      "## Assignment Title: Assignment 3\n",
      "\n",
      "### Description\n",
      "The assignment appears to be a structured task that requires the integration of information from multiple sources. The specific details regarding the content, objectives, or requirements of the assignment are not provided in the available information.\n",
      "\n",
      "### Key Points\n",
      "- **Integration of Sources**: The assignment likely involves synthesizing information from various texts or documents.\n",
      "- **Focus on Analysis**: There may be an emphasis on critical thinking and analysis of the provided materials.\n",
      "\n",
      "### Conclusion\n",
      "Further details regarding the specific objectives, guidelines, or topics covered in Assignment 3 would be necessary to provide a comprehensive understanding of its requirements.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Executive Summary\n# Assignment Overview Report\n\n## Assignment Title: Assignment 3\n\n### Description\nThe assignment appears to be a structured task that requires the integration of information from multiple sources. The specific details regarding the content, objectives, or requirements of the assignment are not provided in the available information.\n\n### Key Points\n- **Integration of Sources**: The assignment likely involves synthesizing information from various texts or documents.\n- **Focus on Analysis**: There may be an emphasis on critical thinking and analysis of the provided materials.\n\n### Conclusion\nFurther details regarding the specific objectives, guidelines, or topics covered in Assignment 3 would be necessary to provide a comprehensive understanding of its requirements.\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### Content from sample-page0-text0 (Page 0)\nAssignment 3\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 02:05:13,314 - __main__ - INFO - Loading cached processing results: storage/cache/Beyond Active and Passive Investing_ The Customization of Finance_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "    processor = DocumentProcessor()\n",
    "    # Load and process documents\n",
    "    documents = processor.process_document(\"/Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf/Beyond Active and Passive Investing_ The Customization of Finance.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", api_base=\"https://models.inference.ai.azure.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 10:14:22,333 - httpx - INFO - HTTP Request: POST https://models.inference.ai.azure.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\"I currently don't have the capability to create or display charts directly. However, I can help you summarize key financial metrics and guide you on how to create charts based on that data. \\n\\nTo summarize key financial metrics, you typically want to focus on the following areas:\\n\\n1. **Revenue**: Total income generated from sales or services.\\n2. **Net Income**: Profit after all expenses, taxes, and costs have been deducted from revenue.\\n3. **Gross Margin**: (Revenue - Cost of Goods Sold) / Revenue, expressed as a percentage.\\n4. **Operating Margin**: Operating Income / Revenue, expressed as a percentage.\\n5. **Net Profit Margin**: Net Income / Revenue, expressed as a percentage.\\n6. **Earnings Per Share (EPS)**: Net Income / Number of Outstanding Shares.\\n7. **Return on Equity (ROE)**: Net Income / Shareholder's Equity, expressed as a percentage.\\n8. **Debt-to-Equity Ratio**: Total Liabilities / Shareholder's Equity, indicating financial leverage.\\n9. **Current Ratio**: Current Assets / Current Liabilities, measuring liquidity.\\n10. **Free Cash Flow**: Cash generated after capital expenditures, indicating the cash available for distribution.\\n\\n### Example Summary\\n\\n**Key Financial Metrics for XYZ Company (2023)**\\n\\n- **Revenue**: $1,000,000\\n- **Net Income**: $200,000\\n- **Gross Margin**: 60%\\n- **Operating Margin**: 25%\\n- **Net Profit Margin**: 20%\\n- **Earnings Per Share (EPS)**: $2.00\\n- **Return on Equity (ROE)**: 15%\\n- **Debt-to-Equity Ratio**: 0.5\\n- **Current Ratio**: 2.0\\n- **Free Cash Flow**: $150,000\\n\\n### Creating Charts\\n\\nTo visualize these metrics, you can use software like Excel, Google Sheets, or any data visualization tool. Heres how you can create charts:\\n\\n1. **Bar Chart for Revenue and Net Income**: Plot revenue and net income side by side to compare.\\n2. **Pie Chart for Profit Margins**: Show the distribution of gross, operating, and net profit margins.\\n3. **Line Chart for EPS and ROE over Time**: If you have historical data, plot EPS and ROE over several years to show trends.\\n4. **Scatter Plot for Debt-to-Equity vs. Current Ratio**: This can help visualize the relationship between leverage and liquidity.\\n\\nIf you provide specific data, I can help you summarize it further or guide you on how to interpret it!\", additional_kwargs={}, raw=ChatCompletion(id='chatcmpl-APt4TBcNVZT7OH5pebS0jcCa9tPwI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I currently don't have the capability to create or display charts directly. However, I can help you summarize key financial metrics and guide you on how to create charts based on that data. \\n\\nTo summarize key financial metrics, you typically want to focus on the following areas:\\n\\n1. **Revenue**: Total income generated from sales or services.\\n2. **Net Income**: Profit after all expenses, taxes, and costs have been deducted from revenue.\\n3. **Gross Margin**: (Revenue - Cost of Goods Sold) / Revenue, expressed as a percentage.\\n4. **Operating Margin**: Operating Income / Revenue, expressed as a percentage.\\n5. **Net Profit Margin**: Net Income / Revenue, expressed as a percentage.\\n6. **Earnings Per Share (EPS)**: Net Income / Number of Outstanding Shares.\\n7. **Return on Equity (ROE)**: Net Income / Shareholder's Equity, expressed as a percentage.\\n8. **Debt-to-Equity Ratio**: Total Liabilities / Shareholder's Equity, indicating financial leverage.\\n9. **Current Ratio**: Current Assets / Current Liabilities, measuring liquidity.\\n10. **Free Cash Flow**: Cash generated after capital expenditures, indicating the cash available for distribution.\\n\\n### Example Summary\\n\\n**Key Financial Metrics for XYZ Company (2023)**\\n\\n- **Revenue**: $1,000,000\\n- **Net Income**: $200,000\\n- **Gross Margin**: 60%\\n- **Operating Margin**: 25%\\n- **Net Profit Margin**: 20%\\n- **Earnings Per Share (EPS)**: $2.00\\n- **Return on Equity (ROE)**: 15%\\n- **Debt-to-Equity Ratio**: 0.5\\n- **Current Ratio**: 2.0\\n- **Free Cash Flow**: $150,000\\n\\n### Creating Charts\\n\\nTo visualize these metrics, you can use software like Excel, Google Sheets, or any data visualization tool. Heres how you can create charts:\\n\\n1. **Bar Chart for Revenue and Net Income**: Plot revenue and net income side by side to compare.\\n2. **Pie Chart for Profit Margins**: Show the distribution of gross, operating, and net profit margins.\\n3. **Line Chart for EPS and ROE over Time**: If you have historical data, plot EPS and ROE over several years to show trends.\\n4. **Scatter Plot for Debt-to-Equity vs. Current Ratio**: This can help visualize the relationship between leverage and liquidity.\\n\\nIf you provide specific data, I can help you summarize it further or guide you on how to interpret it!\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730733257, model='gpt-4o-mini', object='chat.completion', service_tier=None, system_fingerprint='fp_d54531d9eb', usage=CompletionUsage(completion_tokens=547, prompt_tokens=18, total_tokens=565, completion_tokens_details=None, prompt_tokens_details=None)), logprobs=None, delta=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.complete(\"Summarize the key financial metrics and include relevant charts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-dSPC7ywe-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
