{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "from llama_index.core import Settings, StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_index.core import Document, Settings, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import StorageContext\n",
    "import os\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from typing import Sequence\n",
    "import json\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import pymupdf as fitz\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxxxxxx\"\n",
    "pc = Pinecone(api_key=\"xxxxxxx\")\n",
    "# embed_model = OpenAIEmbedding(embed_batch_size=10, api_base=\"https://models.inference.ai.azure.com\")\n",
    "# Settings.embed_model = embed_model\n",
    "# embed_model = HuggingFaceEmbedding(\n",
    "#     model_name=\"BAAI/bge-large-en-v1.5\",  # This has 1024 dimensions\n",
    "#     embed_batch_size=10\n",
    "# )\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "            embed_batch_size=10\n",
    "        )\n",
    "Settings.embed_model = embed_model\n",
    "Settings.dimension = 384\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", api_base=\"https://models.inference.ai.azure.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "import pymupdf as fitz\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from llama_index.core import Document, Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.auto import partition\n",
    "def optimize_metadata(metadata: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Convert complex metadata types to simple types that Pinecone accepts.\n",
    "    Pinecone only accepts strings, numbers, booleans, or lists of strings.\n",
    "    \"\"\"\n",
    "    optimized = {}\n",
    "    \n",
    "    # Handle essential fields\n",
    "    essential_fields = ['source', 'type', 'page_num']\n",
    "    for field in essential_fields:\n",
    "        if field in metadata:\n",
    "            optimized[field] = str(metadata[field])\n",
    "    \n",
    "    # Handle bbox - convert to string representation\n",
    "    if 'bbox' in metadata:\n",
    "        bbox = metadata['bbox']\n",
    "        optimized['bbox_str'] = f\"{bbox['x1']},{bbox['y1']},{bbox['x2']},{bbox['y2']}\"\n",
    "    \n",
    "    # Handle paths - store just the filenames\n",
    "    if 'image' in metadata:\n",
    "        optimized['image_filename'] = os.path.basename(metadata['image'])\n",
    "    if 'dataframe' in metadata:\n",
    "        optimized['excel_filename'] = os.path.basename(metadata['dataframe'])\n",
    "    \n",
    "    # Handle captions\n",
    "    if 'caption' in metadata:\n",
    "        optimized['caption'] = str(metadata['caption'])[:512]  # Limit caption length\n",
    "    \n",
    "    return optimized\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('document_processing.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ProcessingMetrics:\n",
    "    start_time: datetime\n",
    "    end_time: Optional[datetime] = None\n",
    "    document_count: int = 0\n",
    "    total_tokens: int = 0\n",
    "    total_characters: int = 0\n",
    "    processed_files: List[str] = None\n",
    "    errors: List[Dict] = None\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def log_error(self, filename: str, error: Exception):\n",
    "        if self.errors is None:\n",
    "            self.errors = []\n",
    "        self.errors.append({\n",
    "            \"filename\": filename,\n",
    "            \"error\": str(error),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "@dataclass\n",
    "class DocumentElement:\n",
    "    content: Any\n",
    "    element_type: str\n",
    "    page_num: int\n",
    "    bbox: Dict\n",
    "    source_file: str\n",
    "    element_id: str\n",
    "    citations: List[str] = None\n",
    "    \n",
    "    def to_document(self) -> Document:\n",
    "        metadata = {\n",
    "            \"type\": self.element_type,\n",
    "            \"page_num\": self.page_num,\n",
    "            \"bbox\": self.bbox,\n",
    "            \"source\": self.source_file,\n",
    "            \"element_id\": self.element_id,\n",
    "            \"citations\": self.citations\n",
    "        }\n",
    "        \n",
    "        if self.element_type == \"table\":\n",
    "            metadata[\"table_path\"] = self.content[\"table_path\"]\n",
    "            text = f\"Table with caption: {self.content['caption']}\\nColumns: {self.content['columns']}\"\n",
    "        elif self.element_type == \"image\":\n",
    "            metadata[\"image_path\"] = self.content[\"image_path\"]\n",
    "            text = f\"Image with caption: {self.content['caption']}\"\n",
    "        else:\n",
    "            text = self.content\n",
    "            \n",
    "        return Document(text=text, metadata=metadata, id_=self.element_id)\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        self.metrics = ProcessingMetrics(\n",
    "            start_time=datetime.now(),\n",
    "            processed_files=[],\n",
    "            errors=[]\n",
    "        )\n",
    "        \n",
    "        # Initialize models\n",
    "        self.vision_model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.vision_model.to(self.device)\n",
    "        \n",
    "        logger.info(f\"Initialized DocumentProcessor with device: {self.device}\")\n",
    "\n",
    "    def process_text_block(self, text_block: tuple, page_num: int, source_file: str, block_id: int) -> DocumentElement:\n",
    "        \"\"\"Process a text block from PDF.\"\"\"\n",
    "        logger.debug(f\"Processing text block {block_id} from page {page_num}\")\n",
    "        \n",
    "        bbox = {\n",
    "            \"x1\": text_block[0], \n",
    "            \"y1\": text_block[1],\n",
    "            \"x2\": text_block[2], \n",
    "            \"y2\": text_block[3]\n",
    "        }\n",
    "        \n",
    "        self.metrics.total_characters += len(text_block[4])\n",
    "        # Approximate token count\n",
    "        self.metrics.total_tokens += len(text_block[4].split())\n",
    "        \n",
    "        return DocumentElement(\n",
    "            content=text_block[4],\n",
    "            element_type=\"text\",\n",
    "            page_num=page_num,\n",
    "            bbox=bbox,\n",
    "            source_file=source_file,\n",
    "            element_id=f\"{source_file}-page{page_num}-block{block_id}\"\n",
    "        )\n",
    "\n",
    "    def process_table(self, table, page_num: int, source_file: str, table_id: int, \n",
    "                     save_dir: str) -> DocumentElement:\n",
    "        \"\"\"Process a table from PDF.\"\"\"\n",
    "        logger.debug(f\"Processing table {table_id} from page {page_num}\")\n",
    "        \n",
    "        df = table.to_pandas()\n",
    "        table_path = os.path.join(save_dir, f\"table-{table_id}-page-{page_num}.xlsx\")\n",
    "        df.to_excel(table_path, index=False)\n",
    "        \n",
    "        content = {\n",
    "            \"table_path\": table_path,\n",
    "            \"caption\": f\"Table extracted from page {page_num}\",\n",
    "            \"columns\": \", \".join(df.columns.tolist())\n",
    "        }\n",
    "        \n",
    "        # Update metrics\n",
    "        self.metrics.total_characters += sum(df.astype(str).sum().sum())\n",
    "        self.metrics.total_tokens += len(df.columns) * df.shape[0]  # Approximate\n",
    "        \n",
    "        return DocumentElement(\n",
    "            content=content,\n",
    "            element_type=\"table\",\n",
    "            page_num=page_num,\n",
    "            bbox=table.bbox,\n",
    "            source_file=source_file,\n",
    "            element_id=f\"{source_file}-page{page_num}-table{table_id}\"\n",
    "        )\n",
    "\n",
    "    def describe_image(self, image_content: bytes) -> str:\n",
    "        \"\"\"Generate a text description of the image using a pre-trained model.\"\"\"\n",
    "        logger.debug(\"Generating image description\")\n",
    "        \n",
    "        image = Image.open(io.BytesIO(image_content)).convert('RGB')\n",
    "        pixel_values = self.feature_extractor(images=[image], return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.to(self.device)\n",
    "\n",
    "        output_ids = self.vision_model.generate(\n",
    "            pixel_values,\n",
    "            max_length=16,\n",
    "            num_beams=4\n",
    "        )\n",
    "\n",
    "        preds = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        description = preds[0].strip()\n",
    "        \n",
    "        # Update metrics\n",
    "        self.metrics.total_characters += len(description)\n",
    "        self.metrics.total_tokens += len(description.split())\n",
    "        \n",
    "        return description\n",
    "\n",
    "    def is_graph(self, image_data: bytes) -> bool:\n",
    "        \"\"\"Detect if the image contains a graph.\"\"\"\n",
    "        logger.debug(\"Checking if image is a graph\")\n",
    "        \n",
    "        nparr = np.frombuffer(image_data, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "        \n",
    "        return lines is not None and len(lines) > 10\n",
    "\n",
    "    def process_graph(self, image_data: bytes) -> str:\n",
    "        \"\"\"Process a graph image to extract basic information.\"\"\"\n",
    "        logger.debug(\"Processing graph\")\n",
    "        \n",
    "        nparr = np.frombuffer(image_data, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "        \n",
    "        horizontal_lines = 0\n",
    "        vertical_lines = 0\n",
    "        \n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                rho, theta = line[0]\n",
    "                if np.abs(theta) < np.pi / 4 or np.abs(theta - np.pi) < np.pi / 4:\n",
    "                    vertical_lines += 1\n",
    "                else:\n",
    "                    horizontal_lines += 1\n",
    "        \n",
    "        graph_type = \"bar graph\" if vertical_lines > horizontal_lines else \\\n",
    "                    \"line graph\" if horizontal_lines > vertical_lines else \\\n",
    "                    \"scatter plot\"\n",
    "        \n",
    "        description = f\"This image appears to be a {graph_type} with approximately {vertical_lines} vertical lines and {horizontal_lines} horizontal lines.\"\n",
    "        \n",
    "        # Update metrics\n",
    "        self.metrics.total_characters += len(description)\n",
    "        self.metrics.total_tokens += len(description.split())\n",
    "        \n",
    "        return description\n",
    "\n",
    "    def parse_all_tables(self, filename: str, page, pagenum: int, text_blocks, ongoing_tables) -> Tuple[List[Document], List, Any]:\n",
    "        \"\"\"Extract tables from a PDF page.\"\"\"\n",
    "        logger.debug(f\"Parsing tables from page {pagenum}\")\n",
    "        \n",
    "        table_docs = []\n",
    "        table_bboxes = []\n",
    "        \n",
    "        try:\n",
    "            tables = page.find_tables(\n",
    "                horizontal_strategy=\"lines_strict\",\n",
    "                vertical_strategy=\"lines_strict\"\n",
    "            )\n",
    "            \n",
    "            tablerefdir = os.path.join(os.getcwd(), \"vectorstore/table_references\")\n",
    "            os.makedirs(tablerefdir, exist_ok=True)\n",
    "            \n",
    "            for tab in tables:\n",
    "                if not tab.header.external:\n",
    "                    continue\n",
    "                \n",
    "                pandas_df = tab.to_pandas()\n",
    "                df_xlsx_path = os.path.join(\n",
    "                    tablerefdir,\n",
    "                    f\"table{len(table_docs)+1}-page{pagenum}.xlsx\"\n",
    "                )\n",
    "                pandas_df.to_excel(df_xlsx_path)\n",
    "                \n",
    "                bbox = fitz.Rect(tab.bbox)\n",
    "                table_bboxes.append(bbox)\n",
    "                \n",
    "                # Extract surrounding text\n",
    "                before_text, after_text = self.extract_text_around_item(\n",
    "                    text_blocks,\n",
    "                    bbox,\n",
    "                    page.rect.height\n",
    "                )\n",
    "                \n",
    "                # Save table image\n",
    "                table_img = page.get_pixmap(clip=bbox)\n",
    "                table_img_path = os.path.join(\n",
    "                    tablerefdir,\n",
    "                    f\"table{len(table_docs)+1}-page{pagenum}.jpg\"\n",
    "                )\n",
    "                table_img.save(table_img_path)\n",
    "                \n",
    "                description = self.process_graph(table_img.tobytes())\n",
    "                caption = before_text.replace(\"\\n\", \" \") + description + after_text.replace(\"\\n\", \" \")\n",
    "                if before_text == \"\" and after_text == \"\":\n",
    "                    caption = \" \".join(tab.header.names)\n",
    "                \n",
    "                table_metadata = {\n",
    "                    \"source\": f\"{filename[:-4]}-page{pagenum}-table{len(table_docs)+1}\",\n",
    "                    \"excel_path\": df_xlsx_path,\n",
    "                    \"image_path\": table_img_path,\n",
    "                    \"caption\": caption,\n",
    "                    \"type\": \"table\",\n",
    "                    \"page_num\": pagenum,\n",
    "                    \"columns\": list(pandas_df.columns.values),\n",
    "                    \"markdown_table\": pandas_df.to_markdown(),\n",
    "                    \"html_table\": pandas_df.to_html()\n",
    "                }\n",
    "                \n",
    "                doc_text = (\n",
    "                    f\"Table Reference: {table_metadata['markdown_table']}\\n\"\n",
    "                    f\"Caption: {caption}\\n\"\n",
    "                    f\"Excel File: {df_xlsx_path}\\n\"\n",
    "                    f\"Table Image: ![Table]({table_img_path})\"\n",
    "                )\n",
    "                optimized_metadata = optimize_metadata(table_metadata)\n",
    "                table_docs.append(Document(\n",
    "                    text=doc_text,\n",
    "                    metadata=optimized_metadata\n",
    "                ))\n",
    "                \n",
    "                # Update metrics\n",
    "                self.metrics.total_characters += len(doc_text)\n",
    "                self.metrics.total_tokens += len(doc_text.split())\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing tables on page {pagenum}: {e}\")\n",
    "            self.metrics.log_error(filename, e)\n",
    "        \n",
    "        return table_docs, table_bboxes, ongoing_tables\n",
    "\n",
    "    def load_data_from_directory(self, directory: str) -> List[Document]:\n",
    "        \"\"\"Load and process multiple file types from a directory.\"\"\"\n",
    "        logger.info(f\"Processing directory: {directory}\")\n",
    "        \n",
    "        documents = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            file_extension = os.path.splitext(filename.lower())[1]\n",
    "            \n",
    "            logger.info(f\"Processing file: {filename}\")\n",
    "            self.metrics.processed_files.append(filename)\n",
    "            \n",
    "            try:\n",
    "                if file_extension in ('.png', '.jpg', '.jpeg'):\n",
    "                    with open(filepath, \"rb\") as image_file:\n",
    "                        image_content = image_file.read()\n",
    "                        image_text = self.describe_image(image_content)\n",
    "                        doc = Document(\n",
    "                            text=image_text,\n",
    "                            metadata={\"source\": filename, \"type\": \"image\"}\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "                \n",
    "                elif file_extension == '.pdf':\n",
    "                    with open(filepath, \"rb\") as pdf_file:\n",
    "                        pdf_documents = self.get_pdf_documents(pdf_file)\n",
    "                        documents.extend(pdf_documents)\n",
    "                \n",
    "                elif file_extension in ('.ppt', '.pptx'):\n",
    "                    ppt_documents = self.process_ppt_file(filepath)\n",
    "                    documents.extend(ppt_documents)\n",
    "                \n",
    "                else:\n",
    "                    with open(filepath, \"r\", encoding=\"utf-8\") as text_file:\n",
    "                        text = text_file.read()\n",
    "                        doc = Document(\n",
    "                            text=text,\n",
    "                            metadata={\"source\": filename, \"type\": \"text\"}\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "                \n",
    "                self.metrics.document_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {filename}: {e}\")\n",
    "                self.metrics.log_error(filename, e)\n",
    "                continue\n",
    "        \n",
    "        return documents\n",
    "\n",
    "    def export_metrics(self, output_path: str = \"processing_metrics.json\"):\n",
    "        \"\"\"Export processing metrics to JSON file.\"\"\"\n",
    "        self.metrics.end_time = datetime.now()\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(self.metrics.to_dict(), f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"Metrics exported to {output_path}\")\n",
    "        \n",
    "        return self.metrics.to_dict()\n",
    "\n",
    "    # Helper method that needs to be implemented\n",
    "    # ... [Previous code remains the same until extract_text_around_item] ...\n",
    "\n",
    "    def extract_text_around_item(self, text_blocks, bbox, page_height, context_distance: float = 50.0) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Extract text before and after an item on the page within a specified distance.\n",
    "        \n",
    "        Args:\n",
    "            text_blocks: List of text blocks from the page\n",
    "            bbox: Bounding box of the item (table/image)\n",
    "            page_height: Height of the page\n",
    "            context_distance: Distance in points to look for context (default: 50.0)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[str, str]: (text before item, text after item)\n",
    "        \"\"\"\n",
    "        logger.debug(\"Extracting text around item\")\n",
    "        \n",
    "        # Convert bbox to coordinates if it's not already\n",
    "        if isinstance(bbox, dict):\n",
    "            item_top = bbox['y1']\n",
    "            item_bottom = bbox['y2']\n",
    "        else:\n",
    "            item_top = bbox.y0\n",
    "            item_bottom = bbox.y1\n",
    "            \n",
    "        before_text = []\n",
    "        after_text = []\n",
    "        \n",
    "        for block in text_blocks:\n",
    "            # Get the vertical position of the text block\n",
    "            block_bottom = block[3]  # y2\n",
    "            block_top = block[1]     # y1\n",
    "            block_text = block[4]    # text content\n",
    "            \n",
    "            # Check if text is before the item\n",
    "            if block_bottom < item_top and (item_top - block_bottom) <= context_distance:\n",
    "                before_text.append(block_text)\n",
    "                \n",
    "            # Check if text is after the item\n",
    "            elif block_top > item_bottom and (block_top - item_bottom) <= context_distance:\n",
    "                after_text.append(block_text)\n",
    "        \n",
    "        return \" \".join(before_text), \" \".join(after_text)\n",
    "\n",
    "    def get_pdf_documents(self, pdf_file) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Process PDF file and return list of documents.\n",
    "        \n",
    "        Args:\n",
    "            pdf_file: File object of the PDF\n",
    "            \n",
    "        Returns:\n",
    "            List[Document]: List of processed documents\n",
    "        \"\"\"\n",
    "        logger.info(\"Processing PDF file\")\n",
    "        \n",
    "        try:\n",
    "            # Load PDF\n",
    "            pdf_document = fitz.open(stream=pdf_file.read())\n",
    "            documents = []\n",
    "            \n",
    "            for page_num in range(len(pdf_document)):\n",
    "                page = pdf_document[page_num]\n",
    "                \n",
    "                # Get text blocks\n",
    "                text_blocks = page.get_text(\"blocks\")\n",
    "                \n",
    "                # Process tables first\n",
    "                table_docs, table_bboxes, _ = self.parse_all_tables(\n",
    "                    pdf_file.name,\n",
    "                    page,\n",
    "                    page_num + 1,\n",
    "                    text_blocks,\n",
    "                    None\n",
    "                )\n",
    "                documents.extend(table_docs)\n",
    "                \n",
    "                # Process remaining text blocks\n",
    "                for block_id, block in enumerate(text_blocks):\n",
    "                    # Skip if block overlaps with any table\n",
    "                    block_rect = fitz.Rect(block[:4])\n",
    "                    skip_block = any(block_rect.intersects(table_bbox) for table_bbox in table_bboxes)\n",
    "                    \n",
    "                    if not skip_block:\n",
    "                        doc_element = self.process_text_block(\n",
    "                            block,\n",
    "                            page_num + 1,\n",
    "                            pdf_file.name,\n",
    "                            block_id\n",
    "                        )\n",
    "                        documents.append(doc_element.to_document())\n",
    "                \n",
    "                # Process images\n",
    "                images = page.get_images(full=True)\n",
    "                for img_id, img_info in enumerate(images):\n",
    "                    xref = img_info[0]\n",
    "                    base_image = pdf_document.extract_image(xref)\n",
    "                    \n",
    "                    if base_image:\n",
    "                        image_data = base_image[\"image\"]\n",
    "                        \n",
    "                        # Process as graph if detected\n",
    "                        if self.is_graph(image_data):\n",
    "                            description = self.process_graph(image_data)\n",
    "                        else:\n",
    "                            description = self.describe_image(image_data)\n",
    "                        \n",
    "                        # Create image document\n",
    "                        doc = Document(\n",
    "                            text=description,\n",
    "                            metadata={\n",
    "                                \"source\": pdf_file.name,\n",
    "                                \"type\": \"image\",\n",
    "                                \"page_num\": page_num + 1,\n",
    "                                \"image_id\": img_id\n",
    "                            }\n",
    "                        )\n",
    "                        documents.append(doc)\n",
    "            \n",
    "            return documents\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PDF: {e}\")\n",
    "            self.metrics.log_error(pdf_file.name, e)\n",
    "            return []\n",
    "\n",
    "    def process_ppt_file(self, filepath: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Process PowerPoint file and return list of documents.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the PowerPoint file\n",
    "            \n",
    "        Returns:\n",
    "            List[Document]: List of processed documents\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing PowerPoint file: {filepath}\")\n",
    "        \n",
    "        try:\n",
    "            from pptx import Presentation\n",
    "            \n",
    "            documents = []\n",
    "            prs = Presentation(filepath)\n",
    "            \n",
    "            for slide_num, slide in enumerate(prs.slides, 1):\n",
    "                # Process text content\n",
    "                text_content = []\n",
    "                \n",
    "                for shape in slide.shapes:\n",
    "                    if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                        text_content.append(shape.text.strip())\n",
    "                        \n",
    "                        # Update metrics\n",
    "                        self.metrics.total_characters += len(shape.text)\n",
    "                        self.metrics.total_tokens += len(shape.text.split())\n",
    "                \n",
    "                if text_content:\n",
    "                    doc = Document(\n",
    "                        text=\"\\n\".join(text_content),\n",
    "                        metadata={\n",
    "                            \"source\": filepath,\n",
    "                            \"type\": \"presentation\",\n",
    "                            \"slide_num\": slide_num\n",
    "                        }\n",
    "                    )\n",
    "                    documents.append(doc)\n",
    "                \n",
    "                # Process images in the slide\n",
    "                for shape in slide.shapes:\n",
    "                    if hasattr(shape, \"image\"):\n",
    "                        try:\n",
    "                            # Save image temporarily\n",
    "                            image_bytes = shape.image.blob\n",
    "                            \n",
    "                            # Process as graph if detected\n",
    "                            if self.is_graph(image_bytes):\n",
    "                                description = self.process_graph(image_bytes)\n",
    "                            else:\n",
    "                                description = self.describe_image(image_bytes)\n",
    "                            \n",
    "                            doc = Document(\n",
    "                                text=description,\n",
    "                                metadata={\n",
    "                                    \"source\": filepath,\n",
    "                                    \"type\": \"presentation_image\",\n",
    "                                    \"slide_num\": slide_num\n",
    "                                }\n",
    "                            )\n",
    "                            documents.append(doc)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Error processing image in slide {slide_num}: {e}\")\n",
    "                            continue\n",
    "            \n",
    "            return documents\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PowerPoint file: {e}\")\n",
    "            self.metrics.log_error(filepath, e)\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path: str, save_dir: str = \"processed_documents\") -> List[Document]:\n",
    "    \"\"\"Process a PDF file and extract all elements.\"\"\"\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    doc = fitz.open(pdf_path)\n",
    "    elements = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Process text blocks\n",
    "        text_blocks = [block for block in page.get_text(\"blocks\") \n",
    "                      if block[6] == 0]  # Filter for text blocks\n",
    "        \n",
    "        for idx, block in enumerate(text_blocks):\n",
    "            element = process_text_block(block, page_num, pdf_path, idx)\n",
    "            elements.append(element)\n",
    "        \n",
    "        # Process tables\n",
    "        tables = page.find_tables()\n",
    "        for idx, table in enumerate(tables):\n",
    "            element = process_table(table, page_num, pdf_path, idx, save_dir)\n",
    "            elements.append(element)\n",
    "            \n",
    "        # Process images (similar structure)\n",
    "        \n",
    "    return [element.to_document() for element in elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "def initialize_vector_store(index_name: str = \"document-store\") -> PineconeVectorStore:\n",
    "    \"\"\"Initialize Pinecone vector store with the new client.\"\"\"\n",
    "    \n",
    "    # Initialize Pinecone client\n",
    "    pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "    \n",
    "    # Check if index exists, if not create it\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=Settings.dimension,  # OpenAI embedding dimension\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Initialize vector store\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index_name=index_name,\n",
    "        environment=os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
    "    )\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "def create_document_index(documents: List[Document]) -> VectorStoreIndex:\n",
    "    \"\"\"Create searchable index from documents.\"\"\"\n",
    "    vector_store = initialize_vector_store()\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    return VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context,\n",
    "        show_progress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_engine(index: VectorStoreIndex):\n",
    "    \"\"\"Create a query engine with specific configurations.\"\"\"\n",
    "    return index.as_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        response_mode=\"tree_summarize\"\n",
    "    )\n",
    "\n",
    "def search_documents(query: str, index: VectorStoreIndex, \n",
    "                    filters: Dict = None) -> Dict:\n",
    "    \"\"\"Search documents with optional filters.\"\"\"\n",
    "    query_engine = create_query_engine(index)\n",
    "    response = query_engine.query(query)\n",
    "    \n",
    "    # Extract source nodes and metadata\n",
    "    sources = []\n",
    "    for node in response.source_nodes:\n",
    "        sources.append({\n",
    "            \"text\": node.text,\n",
    "            \"metadata\": node.metadata,\n",
    "            \"score\": node.score\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"sources\": sources\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"input_directory\": \"/Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf\",\n",
    "    \"pinecone_api_key\": \"xxxxxxx\",\n",
    "    \"pinecone_environment\": \"us-east1-gcp\",\n",
    "    \"openai_api_key\": \"xxxxxxx\",\n",
    "    \"index_name\": \"document-store\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import pinecone\n",
    "\n",
    "def main(\n",
    "    input_directory: str,\n",
    "    pinecone_api_key: str,\n",
    "    pinecone_environment: str,\n",
    "    openai_api_key: str,\n",
    "    index_name: str = \"document-store\",\n",
    "    batch_size: int = 100\n",
    ") -> Optional[VectorStoreIndex]:\n",
    "    \"\"\"\n",
    "    Main function to process documents and create searchable index.\n",
    "    \n",
    "    Args:\n",
    "        input_directory: Path to directory containing PDFs\n",
    "        pinecone_api_key: Pinecone API key\n",
    "        pinecone_environment: Pinecone environment\n",
    "        openai_api_key: OpenAI API key\n",
    "        index_name: Name of the Pinecone index\n",
    "        batch_size: Number of documents to process in each batch\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up environment variables\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
    "        os.environ[\"PINECONE_ENVIRONMENT\"] = pinecone_environment\n",
    "\n",
    "        # Initialize settings\n",
    "        # embed_model = OpenAIEmbedding(embed_batch_size=10, api_base=\"https://models.inference.ai.azure.com\", model=\"text-embedding-3-small\")\n",
    "        # Settings.embed_model = embed_model\n",
    "        from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Initialize the embedding model        \n",
    "        # Initialize Pinecone\n",
    "        vector_store = initialize_vector_store()\n",
    "\n",
    "        # Create storage context\n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            vector_store=vector_store\n",
    "        )\n",
    "\n",
    "        # Process documents\n",
    "        print(f\"Processing documents from {input_directory}\")\n",
    "        processor = DocumentProcessor()\n",
    "        documents = processor.load_data_from_directory(input_directory)\n",
    "        \n",
    "        if not documents:\n",
    "            print(\"No documents were processed successfully.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Successfully processed {len(documents)} documents\")\n",
    "        \n",
    "        # Create index\n",
    "        print(\"Creating vector index...\")\n",
    "        index = VectorStoreIndex.from_documents(\n",
    "            documents,\n",
    "            storage_context=storage_context,\n",
    "            show_progress=True\n",
    "        )\n",
    "        \n",
    "        print(\"Index created successfully!\")\n",
    "        \n",
    "        # Create a simple query to test the index\n",
    "        # query_engine = index.as_query_engine(\n",
    "        #     similarity_top_k=5,\n",
    "        #     response_mode=\"tree_summarize\"\n",
    "        # )\n",
    "        \n",
    "        # print(\"\\nTesting index with a sample query...\")\n",
    "        # response = query_engine.query(\n",
    "        #     \"What are the main topics covered in these documents?\"\n",
    "        # )\n",
    "        # print(\"\\nSample Query Response:\")\n",
    "        # print(response.response)\n",
    "        \n",
    "        return index\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Usage example\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Configuration\n",
    "#     config = {\n",
    "#         \"input_directory\": \"path/to/your/pdfs\",\n",
    "#         \"pinecone_api_key\": \"your-pinecone-api-key\",\n",
    "#         \"pinecone_environment\": \"your-pinecone-environment\",\n",
    "#         \"openai_api_key\": \"your-openai-api-key\",\n",
    "#         \"index_name\": \"document-store\"\n",
    "#     }\n",
    "    \n",
    "#     # Run the main function\n",
    "#     index = main(**config)\n",
    "    \n",
    "#     if index:\n",
    "#         # Example query\n",
    "#         query_engine = index.as_query_engine()\n",
    "#         response = query_engine.query(\n",
    "#             \"What are the key findings in the documents?\"\n",
    "#         )\n",
    "#         print(\"\\nQuery Response:\")\n",
    "#         print(response.response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained image captioning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_metadata(metadata: dict, max_length: int = 1000) -> dict:\n",
    "    \"\"\"\n",
    "    Strictly optimize metadata size by limiting field lengths and removing non-essential data.\n",
    "    \n",
    "    Args:\n",
    "        metadata: Original metadata dictionary\n",
    "        max_length: Maximum allowed length for metadata\n",
    "    \"\"\"\n",
    "    essential_fields = {\n",
    "        \"source\": 100,  # Max length for source\n",
    "        \"type\": 10,     # Max length for type\n",
    "        \"page_num\": 5,  # Max length for page number\n",
    "        \"caption\": 200  # Max length for caption\n",
    "    }\n",
    "    \n",
    "    optimized = {}\n",
    "    current_length = 0\n",
    "    \n",
    "    for field, max_field_length in essential_fields.items():\n",
    "        if field in metadata:\n",
    "            value = str(metadata[field])\n",
    "            # Truncate value if needed\n",
    "            if len(value) > max_field_length:\n",
    "                value = value[:max_field_length] + \"...\"\n",
    "            \n",
    "            # Check if adding this field would exceed max_length\n",
    "            if current_length + len(field) + len(value) < max_length:\n",
    "                optimized[field] = value\n",
    "                current_length += len(field) + len(value)\n",
    "    \n",
    "    return optimized\n",
    "def process_text_blocks(text_blocks):\n",
    "    \"\"\"Process and group text blocks.\"\"\"\n",
    "    grouped_blocks = []\n",
    "    current_heading = None\n",
    "    current_content = []\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        # Assuming blocks with larger font sizes are headings\n",
    "        if len(block[4].strip()) < 100:  # Short text blocks are likely headings\n",
    "            if current_heading is not None:\n",
    "                grouped_blocks.append((current_heading, \"\\n\".join(current_content)))\n",
    "            current_heading = block\n",
    "            current_content = []\n",
    "        else:\n",
    "            current_content.append(block[4])\n",
    "    \n",
    "    if current_heading is not None:\n",
    "        grouped_blocks.append((current_heading, \"\\n\".join(current_content)))\n",
    "    \n",
    "    return grouped_blocks\n",
    "\n",
    "def extract_text_around_item(text_blocks, item_bbox, page_height, margin=20):\n",
    "    \"\"\"Extract text before and after an item (table/image).\"\"\"\n",
    "    before_text = []\n",
    "    after_text = []\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        block_bbox = fitz.Rect(block[:4])\n",
    "        \n",
    "        # Text before the item\n",
    "        if block_bbox.y1 < item_bbox.y0 - margin:\n",
    "            before_text.append(block[4])\n",
    "        # Text after the item\n",
    "        elif block_bbox.y0 > item_bbox.y1 + margin:\n",
    "            after_text.append(block[4])\n",
    "    \n",
    "    return \" \".join(before_text), \" \".join(after_text)\n",
    "def parse_all_images(filename, page, pagenum, text_blocks):\n",
    "    \"\"\"Extract images from a PDF page.\"\"\"\n",
    "    image_docs = []\n",
    "    \n",
    "    # Get list of images on the page\n",
    "    image_info_list = page.get_image_info(xrefs=True)\n",
    "    page_rect = page.rect\n",
    "    \n",
    "    for image_info in image_info_list:\n",
    "        xref = image_info['xref']\n",
    "        if xref == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get image boundaries\n",
    "        img_bbox = fitz.Rect(image_info['bbox'])\n",
    "        \n",
    "        # Skip very small images (likely icons or decorative elements)\n",
    "        if img_bbox.width < page_rect.width / 20 or img_bbox.height < page_rect.height / 20:\n",
    "            continue\n",
    "            \n",
    "        # Extract image data\n",
    "        extracted_image = page.parent.extract_image(xref)\n",
    "        image_data = extracted_image[\"image\"]\n",
    "        \n",
    "        # Create directory for image storage\n",
    "        imgrefpath = os.path.join(os.getcwd(), \"vectorstore/image_references\")\n",
    "        os.makedirs(imgrefpath, exist_ok=True)\n",
    "        \n",
    "        # Save image\n",
    "        image_path = os.path.join(imgrefpath, f\"image{xref}-page{pagenum}.png\")\n",
    "        with open(image_path, \"wb\") as img_file:\n",
    "            img_file.write(image_data)\n",
    "        \n",
    "        # Get surrounding text\n",
    "        before_text, after_text = extract_text_around_item(text_blocks, img_bbox, page.rect.height)\n",
    "        \n",
    "        # Skip images without any context\n",
    "        if before_text == \"\" and after_text == \"\":\n",
    "            continue\n",
    "        \n",
    "        # Process image content\n",
    "        image_description = \" \"\n",
    "        if is_graph(image_data):\n",
    "            image_description = process_graph(image_data)\n",
    "            \n",
    "        # Create caption from surrounding text and image description\n",
    "        caption = before_text.replace(\"\\n\", \" \") + image_description + after_text.replace(\"\\n\", \" \")\n",
    "        \n",
    "        # Create image metadata\n",
    "        image_metadata = {\n",
    "            \"source\": f\"{filename[:-4]}-page{pagenum}-image{xref}\",\n",
    "            \"image_path\": image_path,  # Actual path to the stored image\n",
    "            \"caption\": caption,\n",
    "            \"type\": \"image\",\n",
    "            \"page_num\": pagenum,\n",
    "            \"markdown_link\": f\"![{caption}]({image_path})\",  # Markdown format\n",
    "            \"html_link\": f'<img src=\"{image_path}\" alt=\"{caption}\" />'  # HTML format\n",
    "        }\n",
    "        print(image_metadata)        \n",
    "        optimized_metadata = optimize_metadata(image_metadata)\n",
    "        doc_text = f\"Image on page {pagenum}: {optimized_metadata.get('caption', '')[:100]}\"\n",
    "        \n",
    "        # Create document with image information\n",
    "        image_docs.append(Document(\n",
    "            text=doc_text,\n",
    "            metadata=optimized_metadata\n",
    "        ))\n",
    "\n",
    "\n",
    "    \n",
    "    return image_docs\n",
    "def get_pdf_documents(pdf_file):\n",
    "    \"\"\"Process a PDF file and extract text, tables, and images.\"\"\"\n",
    "    all_pdf_documents = []\n",
    "    ongoing_tables = {}\n",
    "    \n",
    "    try:\n",
    "        f = fitz.open(stream=pdf_file.read(), filetype=\"pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening or processing the PDF file: {e}\")\n",
    "        return []\n",
    "    \n",
    "    for i in range(len(f)):\n",
    "        page = f[i]\n",
    "        \n",
    "        # Get text blocks (excluding headers and footers)\n",
    "        text_blocks = [\n",
    "            block for block in page.get_text(\"blocks\", sort=True)\n",
    "            if block[-1] == 0 and not (\n",
    "                block[1] < page.rect.height * 0.1 or \n",
    "                block[3] > page.rect.height * 0.9\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Group text blocks\n",
    "        grouped_text_blocks = process_text_blocks(text_blocks)\n",
    "        \n",
    "        # Parse tables\n",
    "        table_docs, table_bboxes, ongoing_tables = parse_all_tables(\n",
    "            pdf_file.name, page, i, text_blocks, ongoing_tables\n",
    "        )\n",
    "        all_pdf_documents.extend(table_docs)\n",
    "        \n",
    "        # Parse images\n",
    "        image_docs = parse_all_images(pdf_file.name, page, i, text_blocks)\n",
    "        all_pdf_documents.extend(image_docs)\n",
    "        \n",
    "        # Process text blocks\n",
    "        for text_block_ctr, (heading_block, content) in enumerate(grouped_text_blocks, 1):\n",
    "            heading_bbox = fitz.Rect(heading_block[:4])\n",
    "            \n",
    "            # Skip if the text block intersects with a table\n",
    "            if not any(heading_bbox.intersects(table_bbox) for table_bbox in table_bboxes):\n",
    "                bbox = {\n",
    "                    \"x1\": heading_block[0],\n",
    "                    \"y1\": heading_block[1],\n",
    "                    \"x2\": heading_block[2],\n",
    "                    \"x3\": heading_block[3]\n",
    "                }\n",
    "                \n",
    "                text_doc = Document(\n",
    "                    text=f\"{heading_block[4]}\\n{content}\",\n",
    "                    metadata={\n",
    "                        **bbox,\n",
    "                        \"type\": \"text\",\n",
    "                        \"page_num\": i,\n",
    "                        \"source\": f\"{pdf_file.name[:-4]}-page{i}-block{text_block_ctr}\"\n",
    "                    },\n",
    "                    id_=f\"{pdf_file.name[:-4]}-page{i}-block{text_block_ctr}\"\n",
    "                )\n",
    "                all_pdf_documents.append(text_doc)\n",
    "    \n",
    "    f.close()\n",
    "    return all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 18:34:12,349 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/saisuryamadhav/Library/Caches/pypoetry/virtualenvs/backend-dSPC7ywe-py3.12/lib/python3.12/site-packages/pinecone_plugins'])\n",
      "2024-11-03 18:34:12,352 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2024-11-03 18:34:12,353 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n",
      "2024-11-03 18:34:12,834 - pinecone_plugin_interface.logging - INFO - Discovering subpackages in _NamespacePath(['/Users/saisuryamadhav/Library/Caches/pypoetry/virtualenvs/backend-dSPC7ywe-py3.12/lib/python3.12/site-packages/pinecone_plugins'])\n",
      "2024-11-03 18:34:12,836 - pinecone_plugin_interface.logging - INFO - Looking for plugins in pinecone_plugins.inference\n",
      "2024-11-03 18:34:12,837 - pinecone_plugin_interface.logging - INFO - Installing plugin inference into Pinecone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents from /Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.46.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'> is overwritten by shared decoder config: GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "2024-11-03 18:34:21,854 - __main__ - INFO - Initialized DocumentProcessor with device: cpu\n",
      "2024-11-03 18:34:21,856 - __main__ - INFO - Processing directory: /Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf\n",
      "2024-11-03 18:34:21,857 - __main__ - INFO - Processing file: Beyond Active and Passive Investing_ The Customization of Finance.pdf\n",
      "2024-11-03 18:34:21,857 - __main__ - INFO - Processing PDF file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 1567 documents\n",
      "Creating vector index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba59472ac9745a89c159eb71d0e7fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d8f9ad476e4417b92da1bf4bfe8907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6514f7fb18847578e7734c501afad9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80386cc831f14f71b39ccc09853d7741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1c03182c634cd2948edae208037f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d3c71663014a65ba8c3da354214be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2fab915a97485a9261e17da8a6dd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363ef109eeff4d0b8b43c2c2ee455af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfc9742f9bc4a049678ee35527e146a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e807eff4bc4b579507c0e1df7c6165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115e8f0508e646acb2f5f8266dff8433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3877c94b08034f4c881bd756493bcfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c778d1d3f2484a519c4f753e1b899251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707444e90fb24864babcc4fe0631ae28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75dabfdfd1464d4fb846c135bd7c05ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b593f2be7ac0457b94041b60f4e30c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8465a8e65b5e4f4092d7b07bcf1d0c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37b7906178049d1bb214082fdc6eede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5ae6cdb5a34f47827b4a57fdff02b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cd1b7c5aff4f41b5b0582d15b45751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f998fcf9ec47988371e97f1b609ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc21e6b0f4a4b75899a0936b4c24b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447566cd47564c2397a47ebf585cb84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60a92c490064c1390dbdd4ef7fcf0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495459fc59324e6c854ad410a011927e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4481a157e4b944b387211bf97ad08a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdafbe7b073a4097b8c35e789a7fec0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987da0f8954e4a17a11976b408bbe9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e60dc3125b46769e143689ff0e2d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57eac3b3ae64a79856da63e5e8d07b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b8ecf8cbdf4a228229e20e607ef903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77db2b689ea54ae2bdcab07047601bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7664f44c6b5449449badc53138ed5ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d454bed7a81b430b9143931d9b35bf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36ead9edc9143059f44eedb53f25d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97919e97e0b94ad7ad321ddd79c4128d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8899d553fb64ac481b625f8d39d1350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790e25dc77474474a85fd3d7916186b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00f47ebd30c4d65868d4e37327790ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf9af7784b549b8bac8267e5c82459f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b50e48f8cc84e87ac2139ea383bb6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3661e57f7efb4010af5c6e06f05ff872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202429aec635428ab292c5eb24190c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2961173a66b8444d9c4b2755228ae580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016805e202a5430d850768e57b366e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d0a5e02291484cb4df6af06a5d1e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89af2bf46ba4d0da55f7aeb8d99010c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dee396a8b6743599e4771b78ccfba04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa0d3c16eab47ff99d6c80ed0658fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5057601a5a664a06a7cac214095f71af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3784fff20a024198b7b703a08a2d3c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcf250f34c64ede9b97df831c5792ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaac8c96eea4be983ae40d42d812e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0098674b4eed48c5b83bf90ad706c035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5418deae1280423199d8faeafb60186c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfb09f2b3974f329e6861e62cad52c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3efeda63e8c4158bbf4278d27a9daed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387dcfabfb614c78b3657ecd5b666123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e5cf4b91c94d23a5ee8becee319704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4f6bd0f23749d3a0aa22d2d9128070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1fd08b4d444b659aaf582425b4ea44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399356451049442097c4b65c0524698b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84785d7e0079416cb5e788ef63150f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af10320e645f44a9a2ccf2e02876b2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafd9c1900774011b9565bc702f8c1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7635bcf4a14cc9b08c5c04ffada321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac77961df06439e9418fb77b44b365f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5920ce365861470fad800ee2794824cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a78ace4385e4892b7be89dcb29f0b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f390c35f0545ec8444e921907fa068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d566662d134fa7b35df137b68e5be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf534da789847f6af7f047f6883c04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c030d989c7d44b2ba52854e9afc2e5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f742f0b88b49839ce7b33c5d98cd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d00258b8c864dc6afffe0e7b3adee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e65f0dda24af9a3ccec5501da8402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2490c9e92dc4ef9a9b4ae7c3216ab6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062bc4864a154a3eb5501c3be859841a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3ef4c405a44a8bb7a3fd2f3cc182ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c8fbf96e0f4c148765a7838b299222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655b2a6f1286428d9f5082dcda8fb30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e047d9459ba4488eb02fc06930f41579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baa22390d1542e2bd4dbddf234bfc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddf105c2c8c45f3af2a84754d2bd6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b99a68c3c1482c96d211e6723d53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9e4513c3f84bc9a03240e07eac8882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271bfdbac5cc4398ad52db4214f49159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4472bea3f7804725894103a99f8149a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb93b25930b4c2fbcc7153331572e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4919f585c2346fab037e5c0014c6e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651cc609ce894e468ccf4b947501a471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab7bb119c0d47a796ef75d58ee35517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee48bcedeac48cd8015666786fd1c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536aa92d9b8b40598530c42ac9ded5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5267237baa084e64985a0644ba9e0de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467598a25efd420aa7e769515329f5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ec1f44b0594ea18eab2a42007e8f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574d0ee2e4d24fd8b25bd8662d026f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651070ad95ae4184b169be60c479d756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a45cf1fc41543e88adea23346f2d87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4785bd017290461699d54b9e1c18c6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20136e0256814ce3b2dd6db35cfb5224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b32cbfd96b4377b7fdd70a8acf6428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4944ff707724ff4a927f01abf594c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a3a32f10c74fa9a96d328e9b02024c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a53f7259441c3a2b6299583a31a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5a0582d67149c88ce942eb513bd6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec70b37e01e045189037742779a4ed20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdab6f9591f4f5baaf83db3db5d724b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1465fd27a294215a24ad1a7f5d63e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a405d07df754319bfc7c60e6d4560dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643830c8b8304c8792ff96f16e45f963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2f33f330294cf287237a39b7279384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b302bda3cead4d4a99f28e16995dfcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e363f5f7b86642e5808a14d1bc09c219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1efacd7d1347dabb48e81a4b5a30ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec027c4e5c2e4bd38b2797363ca9e941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590ee1f2d01248569e8642775b076c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529b6629c2f845c8a9864a042c5a255d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc586647729945c282b3391a05a35bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a470fa988ff94237bfe9e35207447c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bbc16b5ec64bdc9f5807dde45df6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1122036f7d5c42df97fa401786250c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deeb5a29f514ba08fa0d70de4a7a94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dd9aa43cf8445e81281ca9875cb9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf5104d69534eeba10fc6f33b63fbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5aa04427e234ba1a40c9fa62e826c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d01da1b3924a569edd4b013f9fe024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f709530ff0247b794aa08805307c7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec4402d1cb84b45b84a1babd6b9d2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe6eb4f0e074276801dadc0e317beb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cd3990bc314408a859402d8ca5be63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cafa100968a489dbf2906cc675dbfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f0d7e57ba0448cb1243ad722819ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33065bb211ef4e4eadf6b682fb70a925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b135453a8fe046d7979aef32d5fec5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b654305548344b359cab55930803162b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d571f6470d764956af3916c5787a850a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c49564e06184b60b7908c982aee0e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbfb27ba1e24901bfcb5b9c008a2dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438445f8ac7c4880938b5e394dc75729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f083cd3172448bba3437c9a0b4b18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eaab30b38d447e98fd641f2252c0282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075e62d6757c43b080520de7a4843753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4989895d729e49c19ec6b7dd331c52b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35360bfb9524612b4c9dd482072c81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bdd86be7b1439eb6a911e775bc53ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f377582817436c8119ba2015f063ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28623787f8e3463f96d1bae7cada3a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab026c733f142a09a3504b355e63522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c065c3d65c244779ee6234188d1cf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b49eceea0e941a2a29062409f4322aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95146526fa1b41c5a46ca9689a84aef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c965081c524c47a75bf8f3fc5abc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a3bf3c0efa4bf29eb6d97995c3eea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426b17c6416848b6b41290be40c52810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81faf65150e24123907eb92664fe5806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ef5dcb0de847a8a23cd0ce207be301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0931a230479541dba14e715034a34d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8b182c86834446995b10600a2510f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/1567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: (400)\n",
      "Reason: Bad Request\n",
      "HTTP response headers: HTTPHeaderDict({'Date': 'Sun, 03 Nov 2024 23:35:18 GMT', 'Content-Type': 'application/json', 'Content-Length': '137', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '545', 'x-pinecone-request-id': '5088439913520431194', 'x-envoy-upstream-service-time': '43', 'server': 'envoy'})\n",
      "HTTP response body: {\"code\":3,\"message\":\"Metadata value must be a string, number, boolean or list of strings, got 'null' for field 'citations'\",\"details\":[]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the main processing\n",
    "Settings.chunk_size = 1024 \n",
    "Settings.chunk_overlap = 20\n",
    "Settings.metadata_max_length = 1000  # Add metadata length limit\n",
    "index = main(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'as_query_engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_query_engine\u001b[49m(\n\u001b[1;32m      2\u001b[0m             similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      3\u001b[0m             response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_summarize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m         )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting index with a sample query...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the main topics covered in these documents?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'as_query_engine'"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "            similarity_top_k=5,\n",
    "            response_mode=\"tree_summarize\"\n",
    "        )\n",
    "        \n",
    "print(\"\\nTesting index with a sample query...\")\n",
    "response = query_engine.query(\n",
    "    \"What are the main topics covered in these documents?\"\n",
    ")\n",
    "print(\"\\nSample Query Response:\")\n",
    "print(response.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def initialize_query_engine(\n",
    "    pinecone_api_key: str,\n",
    "    pinecone_environment: str,\n",
    "    openai_api_key: str,\n",
    "    index_name: str = \"document-store\"\n",
    ") -> VectorStoreIndex:\n",
    "    \"\"\"\n",
    "    Initialize connection to existing Pinecone index and create query interface.\n",
    "    \n",
    "    Args:\n",
    "        pinecone_api_key: Pinecone API key\n",
    "        pinecone_environment: Pinecone environment\n",
    "        openai_api_key: OpenAI API key\n",
    "        index_name: Name of the existing Pinecone index\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up environment variables\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "        os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
    "        os.environ[\"PINECONE_ENVIRONMENT\"] = pinecone_environment\n",
    "\n",
    "        # Initialize embedding model\n",
    "        # embed_model = OpenAIEmbedding(\n",
    "        #     embed_batch_size=10,\n",
    "        #     api_base=\"https://models.inference.ai.azure.com\",\n",
    "        #     model=\"text-embedding-3-small\"\n",
    "        # )\n",
    "        # Settings.embed_model = embed_model\n",
    "        Settings.llm = OpenAI(api_base=\"https://models.inference.ai.azure.com\", model=\"gpt-4o-mini\")\n",
    "\n",
    "        # Initialize vector store with existing index\n",
    "        vector_store = PineconeVectorStore(\n",
    "            index_name=index_name,\n",
    "            environment=pinecone_environment\n",
    "        )\n",
    "\n",
    "        # Create storage context\n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            vector_store=vector_store\n",
    "        )\n",
    "\n",
    "        # Create index from existing vector store\n",
    "        index = VectorStoreIndex.from_vector_store(\n",
    "            vector_store,\n",
    "            storage_context=storage_context\n",
    "        )\n",
    "\n",
    "        return index\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Usage example\n",
    "def format_query_response(response, query_type=\"general\"):\n",
    "    \"\"\"Format query response based on content type.\"\"\"\n",
    "    \n",
    "    if query_type == \"images\":\n",
    "        formatted_response = \"Here are the relevant images:\\n\\n\"\n",
    "        for node in response.source_nodes:\n",
    "            if node.metadata.get(\"type\") == \"image\":\n",
    "                formatted_response += (\n",
    "                    f\"## Image on page {node.metadata['page_num']}\\n\"\n",
    "                    f\"{node.metadata['markdown_link']}\\n\"\n",
    "                    f\"**Caption:** {node.metadata['caption']}\\n\\n\"\n",
    "                )\n",
    "    \n",
    "    elif query_type == \"tables\":\n",
    "        formatted_response = \"Here are the relevant tables:\\n\\n\"\n",
    "        for node in response.source_nodes:\n",
    "            if node.metadata.get(\"type\") == \"table\":\n",
    "                formatted_response += (\n",
    "                    f\"## Table from {node.metadata['source']}\\n\"\n",
    "                    f\"{node.metadata['markdown_table']}\\n\"\n",
    "                    f\"**Caption:** {node.metadata['caption']}\\n\"\n",
    "                    f\"[Download Excel]({node.metadata['excel_path']})\\n\\n\"\n",
    "                )\n",
    "    \n",
    "    else:\n",
    "        formatted_response = response.response\n",
    "    \n",
    "    return formatted_response\n",
    "\n",
    "# Usage example\n",
    "def query_documents(query: str, index: VectorStoreIndex):\n",
    "    query_engine = index.as_query_engine(\n",
    "        similarity_top_k=5,\n",
    "        response_mode=\"tree_summarize\"\n",
    "    )\n",
    "    \n",
    "    # Determine query type\n",
    "    query_type = \"general\"\n",
    "    if \"image\" in query.lower():\n",
    "        query_type = \"images\"\n",
    "    elif \"table\" in query.lower():\n",
    "        query_type = \"tables\"\n",
    "    \n",
    "    # Get and format response\n",
    "    response = query_engine.query(query)\n",
    "    formatted_response = format_query_response(response, query_type)\n",
    "    \n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What are the main topics covered?\n",
      "Response: The main topics covered include the analysis of the active versus passive investing debate, focusing on the examination of publicly available funds, specifically open-end mutual funds and exchange-traded funds (ETFs) from 1989 to 2021. The discussion highlights the legal structures of these funds, the significance of asset flows and assets under management (AUM), and the complexities in distinguishing between active and passive fund strategies. Additionally, the categorization of funds into various global categories and the evolution of index funds, including the impact of factor investing and smart beta, are explored. The distribution of active and passive investing across different regions and categories is also addressed.\n",
      "\n",
      "Query: Show me any tables related to financial data\n",
      "Response: Here are the tables related to financial data:\n",
      "\n",
      "1. **Exhibit 29** (Page 42)\n",
      "   - **Columns**: Category, Active (%), Col2, Col3, Col4, Index (%), Col6, Col7, Col8\n",
      "   - **Caption**: Contains granular line-item details for each classification plotted in Exhibit 28.\n",
      "\n",
      "2. **Table** (Page 16)\n",
      "   - **Columns**: United States, Europe, Rest of the World (ROW)\n",
      "   - **Caption**: Represents financial data segmented by geographical regions.\n",
      "\n",
      "3. **Table** (Page 76)\n",
      "   - **Columns**: Characteristic, Traditional Advisory Accounts, Hyper-Managed Accounts\n",
      "   - **Caption**: Compares characteristics of different account types in financial advisory.\n",
      "\n",
      "4. **Table** (Page 52)\n",
      "   - **Columns**: Category, Active (%), Col2, Col3, Col4, Index (%), Col6, Col7, Col8\n",
      "   - **Caption**: Similar structure to Exhibit 29, detailing financial categories and their active percentages.\n",
      "\n",
      "5. **Table** (Page 51)\n",
      "   - **Columns**: Category, Active (%), Col2, Col3, Col4, Index (%), Col6, Col7, Col8\n",
      "   - **Caption**: Another table with a similar structure, providing financial data on various categories.\n",
      "\n",
      "These tables provide insights into different aspects of financial data, including investment classifications, geographical distributions, and account characteristics.\n",
      "\n",
      "Query: What images are present in the documents?\n",
      "Response: The documents contain the following images:\n",
      "\n",
      "1. An image associated with page 42, which appears to be a line graph with approximately 193 vertical lines and 1160 horizontal lines.\n",
      "2. An image associated with page 45, which appears to be a line graph with approximately 131 vertical lines and 782 horizontal lines.\n",
      "3. An image associated with page 77, which appears to be a line graph with approximately 155 vertical lines and 917 horizontal lines.\n",
      "4. An image associated with page 39, which appears to be a line graph with approximately 1309 vertical lines and 1845 horizontal lines.\n",
      "5. An image associated with page 51, which does not have a specific description but is linked to a table.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    # \"input_directory\": \"/Users/saisuryamadhav/Documents/University/new/Assignment_3_Team1/backend/pdf\",\n",
    "    \"pinecone_api_key\": \"xxxxxxx\",\n",
    "    \"pinecone_environment\": \"us-east1-gcp\",\n",
    "    \"openai_api_key\": \"xxxxxxx\",\n",
    "    \"index_name\": \"document-store\"\n",
    "}\n",
    "index = initialize_query_engine(**config)\n",
    "\n",
    "if index:\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"What are the main topics covered?\",\n",
    "        \"Show me any tables related to financial data\",\n",
    "        \"What images are present in the documents?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        response = query_documents(query, index)\n",
    "        print(\"Response:\", response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-dSPC7ywe-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
